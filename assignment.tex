% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={draft},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{draft}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

\section{Exploratory analysis}\label{exploratory-analysis}

\begin{verbatim}
##        ID            AGE          GENDER     DRIVING_EXPERIENCE
##  Min.   :   101   16-25:2016   female:5010   0-9y  :3530       
##  1st Qu.:249639   26-39:3063   male  :4990   10-19y:3299       
##  Median :501777   40-64:2931                 20-29y:2119       
##  Mean   :500522   65+  :1990                 30y+  :1052       
##  3rd Qu.:753975                                                
##  Max.   :999976                                                
##                                                                
##        EDUCATION     CREDIT_SCORE     VEHICLE_OWNERSHIP      VEHICLE_YEAR 
##  high school:4157   Min.   :0.05336   Min.   :0.000     after 2015 :3033  
##  none       :1915   1st Qu.:0.41719   1st Qu.:0.000     before 2015:6967  
##  university :3928   Median :0.52503   Median :1.000                       
##                     Mean   :0.51581   Mean   :0.697                       
##                     3rd Qu.:0.61831   3rd Qu.:1.000                       
##                     Max.   :0.96082   Max.   :1.000                       
##                     NA's   :982                                           
##     MARRIED          CHILDREN      ANNUAL_MILEAGE      VEHICLE_TYPE 
##  Min.   :0.0000   Min.   :0.0000   Min.   : 2000   sedan     :9523  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:10000   sports car: 477  
##  Median :0.0000   Median :1.0000   Median :12000                    
##  Mean   :0.4982   Mean   :0.6888   Mean   :11697                    
##  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:14000                    
##  Max.   :1.0000   Max.   :1.0000   Max.   :22000                    
##                                    NA's   :957                      
##  SPEEDING_VIOLATIONS PAST_ACCIDENTS      OUTCOME           CLAIMS      
##  Min.   : 0.000      Min.   : 0.000   Min.   :0.0000   Min.   :     0  
##  1st Qu.: 0.000      1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:     0  
##  Median : 0.000      Median : 0.000   Median :0.0000   Median :     0  
##  Mean   : 1.483      Mean   : 1.056   Mean   :0.3133   Mean   :  2329  
##  3rd Qu.: 2.000      3rd Qu.: 2.000   3rd Qu.:1.0000   3rd Qu.:  1748  
##  Max.   :22.000      Max.   :15.000   Max.   :1.0000   Max.   :116328  
## 
\end{verbatim}

\subsection{splitting data into train and
test/validation}\label{splitting-data-into-train-and-testvalidation}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{67}\NormalTok{)}
\NormalTok{train\_indices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{,}\DecValTok{8000}\NormalTok{)}
\NormalTok{train\_data }\OtherTok{\textless{}{-}}\NormalTok{ data[train\_indices, ]}
\NormalTok{test\_data }\OtherTok{\textless{}{-}}\NormalTok{ data[}\SpecialCharTok{{-}}\NormalTok{train\_indices, ]}


\NormalTok{train\_data\_x }\OtherTok{\textless{}{-}}\NormalTok{ train\_data }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{OUTCOME, }\SpecialCharTok{{-}}\NormalTok{CLAIMS)}
\NormalTok{test\_data\_x }\OtherTok{\textless{}{-}}\NormalTok{ test\_data }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{OUTCOME, }\SpecialCharTok{{-}}\NormalTok{CLAIMS)}
\end{Highlighting}
\end{Shaded}

\subsection{correlation matrix of numeric
covariates}\label{correlation-matrix-of-numeric-covariates}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num\_cols }\OtherTok{\textless{}{-}}\NormalTok{  data }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric))}

\NormalTok{num\_cols }\OtherTok{\textless{}{-}}\NormalTok{  num\_cols[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(num\_cols}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE) }\SpecialCharTok{\&} 
                      \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(num\_cols}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE),]}
\NormalTok{num\_cols }\OtherTok{\textless{}{-}}\NormalTok{  num\_cols }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{ID)}
\FunctionTok{corrplot}\NormalTok{(}\FunctionTok{cor}\NormalTok{(num\_cols), }\AttributeTok{type =} \StringTok{"lower"}\NormalTok{, }\AttributeTok{diag =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-4-1.pdf}}
- Annual mileage is lower for married ppl and ppl with children - past
accidents has high corr with speeding violations ofc - vehicle owners
are less likely to file claims?

\subsection{investigating missing
values}\label{investigating-missing-values}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"number of rows with missing annual mileage"}\NormalTok{, }
            \FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE)), }\StringTok{"/8000"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "number of rows with missing annual mileage 773 /8000"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"number of rows with missing creditscore"}\NormalTok{, }
            \FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE)), }\StringTok{"/8000"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "number of rows with missing creditscore 804 /8000"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"number of rows missing both annual mileage and credit"}\NormalTok{, }
            \FunctionTok{sum}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE) }\SpecialCharTok{\&} \FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE)), }\StringTok{"/8000"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "number of rows missing both annual mileage and credit 76 /8000"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"percentage of ppl of claim for nonempty annual mileage rows"}\NormalTok{, }
            \FunctionTok{mean}\NormalTok{(train\_data[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE),}\StringTok{"OUTCOME"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T])))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "percentage of ppl of claim for nonempty annual mileage rows 0.31451501314515"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"percentage of ppl of claim for empty annual mileage rows"}\NormalTok{, }
            \FunctionTok{mean}\NormalTok{(train\_data[}\FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE),}\StringTok{"OUTCOME"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T])))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "percentage of ppl of claim for empty annual mileage rows 0.33764553686934"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"percentage of ppl of claim for nonempty creditscore rows"}\NormalTok{, }
            \FunctionTok{mean}\NormalTok{(train\_data[}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE),}\StringTok{"OUTCOME"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T])))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "percentage of ppl of claim for nonempty creditscore rows 0.317259588660367"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"percentage of ppl of claim for empty creditscore rows"}\NormalTok{, }
            \FunctionTok{mean}\NormalTok{(train\_data[}\FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE),}\StringTok{"OUTCOME"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T])))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "percentage of ppl of claim for empty creditscore rows 0.312189054726368"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(}\FunctionTok{log}\NormalTok{(train\_data[train\_data}\SpecialCharTok{$}\NormalTok{CLAIMS}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{,}\StringTok{"CLAIMS"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T]) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{is.na}\NormalTok{(train\_data[train\_data}\SpecialCharTok{$}\NormalTok{CLAIMS}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{,}\StringTok{"ANNUAL\_MILEAGE"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T]),}
        \AttributeTok{xlab =} \StringTok{"is annual mileage missing?"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"log(claim size)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-5-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(}\FunctionTok{log}\NormalTok{(train\_data[train\_data}\SpecialCharTok{$}\NormalTok{CLAIMS}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{,}\StringTok{"CLAIMS"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T]) }\SpecialCharTok{\textasciitilde{}} \FunctionTok{is.na}\NormalTok{(train\_data[train\_data}\SpecialCharTok{$}\NormalTok{CLAIMS}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{,}\StringTok{"CREDIT\_SCORE"}\NormalTok{, }\AttributeTok{drop =}\NormalTok{ T]),}
        \AttributeTok{xlab =} \StringTok{"is creditscore missing?"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"log(claim size)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-5-2.pdf}}

\begin{itemize}
\tightlist
\item
  Dont want to get rid of \textasciitilde10\% of the data, would be good
  to impute
\end{itemize}

Investigating if emptiness of the creditscore is independent to other
variables i.e if creditscore is intentionally left empty - would expect
younger ppl to have no credit score, so cells may be intentionally empty

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{"TESTING FOR INDEPENDENCE OF CREDIT\_SCORE EMPTINESS"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "TESTING FOR INDEPENDENCE OF CREDIT_SCORE EMPTINESS"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define the target variable: a binary indicator for missing credit scores}
\NormalTok{credit\_score\_missing }\OtherTok{\textless{}{-}} \FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE)}

\CommentTok{\# Get a list of all predictor variables to test, excluding ID and CREDIT\_SCORE itself}
\NormalTok{predictors\_to\_test }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}\FunctionTok{names}\NormalTok{(train\_data), }\FunctionTok{c}\NormalTok{(}\StringTok{"ID"}\NormalTok{, }\StringTok{"CREDIT\_SCORE"}\NormalTok{))}

\CommentTok{\# Loop through each predictor and perform the appropriate test}
\ControlFlowTok{for}\NormalTok{ (var }\ControlFlowTok{in}\NormalTok{ predictors\_to\_test) \{}
  
  \CommentTok{\# Ignore any columns with no variation}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(train\_data[[var]])) }\SpecialCharTok{\textless{}} \DecValTok{2}\NormalTok{) }\ControlFlowTok{next}
  
  \CommentTok{\# {-}{-}{-} Test for association with CONTINUOUS variables {-}{-}{-}}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.numeric}\NormalTok{(train\_data[[var]])) \{}
    \CommentTok{\# We use a t{-}test to see if the mean of the numeric variable is}
    \CommentTok{\# different between the \textquotesingle{}missing\textquotesingle{} and \textquotesingle{}present\textquotesingle{} groups.}
\NormalTok{    test\_result }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(train\_data[[var]] }\SpecialCharTok{\textasciitilde{}}\NormalTok{ credit\_score\_missing)}
\NormalTok{    p\_value }\OtherTok{\textless{}{-}}\NormalTok{ test\_result}\SpecialCharTok{$}\NormalTok{p.value}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Variable: \%{-}20s | Test: T{-}test         | P{-}value: \%.4f}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, var, p\_value))}
    
  \CommentTok{\# {-}{-}{-} Test for association with CATEGORICAL variables {-}{-}{-}}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.factor}\NormalTok{(train\_data[[var]]) }\SpecialCharTok{||} \FunctionTok{is.character}\NormalTok{(train\_data[[var]])) \{}
    \CommentTok{\# We use a Chi{-}squared test for independence between two categorical variables.}
    \CommentTok{\# We add \textquotesingle{}simulate.p.value = TRUE\textquotesingle{} to handle cases with low expected counts.}
\NormalTok{    test\_result }\OtherTok{\textless{}{-}} \FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(train\_data[[var]], credit\_score\_missing), }\AttributeTok{simulate.p.value =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    p\_value }\OtherTok{\textless{}{-}}\NormalTok{ test\_result}\SpecialCharTok{$}\NormalTok{p.value}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Variable: \%{-}20s | Test: Chi{-}squared    | P{-}value: \%.4f}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, var, p\_value))}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Variable: AGE                  | Test: Chi-squared    | P-value: 0.1544
## Variable: GENDER               | Test: Chi-squared    | P-value: 0.9025
## Variable: DRIVING_EXPERIENCE   | Test: Chi-squared    | P-value: 0.1494
## Variable: EDUCATION            | Test: Chi-squared    | P-value: 0.5927
## Variable: VEHICLE_OWNERSHIP    | Test: T-test         | P-value: 0.1828
## Variable: VEHICLE_YEAR         | Test: Chi-squared    | P-value: 0.0395
## Variable: MARRIED              | Test: T-test         | P-value: 0.4997
## Variable: CHILDREN             | Test: T-test         | P-value: 0.4530
## Variable: ANNUAL_MILEAGE       | Test: T-test         | P-value: 0.6424
## Variable: VEHICLE_TYPE         | Test: Chi-squared    | P-value: 0.4308
## Variable: SPEEDING_VIOLATIONS  | Test: T-test         | P-value: 0.7981
## Variable: PAST_ACCIDENTS       | Test: T-test         | P-value: 0.9907
## Variable: OUTCOME              | Test: T-test         | P-value: 0.7688
## Variable: CLAIMS               | Test: T-test         | P-value: 0.1725
\end{verbatim}

\begin{itemize}
\tightlist
\item
  pvalues very high, so likely that annual\_mileage is left empty
  independently of other variables for all except vehicle year
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_data }\OtherTok{\textless{}{-}}\NormalTok{ train\_data }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# Create a clear factor for whether the credit score is missing}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Credit\_Score\_Status =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(CREDIT\_SCORE), }\StringTok{"Empty"}\NormalTok{, }\StringTok{"Not Empty"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# Count the occurrences of each vehicle year for each status}
  \FunctionTok{count}\NormalTok{(VEHICLE\_YEAR, Credit\_Score\_Status) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# Group by the status so we can calculate proportions within each group}
  \FunctionTok{group\_by}\NormalTok{(Credit\_Score\_Status) }\SpecialCharTok{\%\textgreater{}\%}
  \CommentTok{\# Calculate the proportion}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Proportion =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n))}


\CommentTok{\# {-}{-}{-} 4. Create the Side{-}by{-}Side Bar Plot {-}{-}{-}}

\FunctionTok{ggplot}\NormalTok{(plot\_data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ VEHICLE\_YEAR, }\AttributeTok{y =}\NormalTok{ Proportion, }\AttributeTok{fill =}\NormalTok{ Credit\_Score\_Status)) }\SpecialCharTok{+}
  \CommentTok{\# geom\_bar with stat="identity" uses the y{-}value directly.}
  \CommentTok{\# position="dodge" places the bars next to each other.}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+}
  
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Vehicle Year Distribution by Credit Score Availability"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Comparing proportions for policies with empty vs. non{-}empty credit scores"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"Vehicle Year"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Proportion within Group"}\NormalTok{,}
    \AttributeTok{fill =} \StringTok{"Credit Score Status"}
\NormalTok{  ) }\SpecialCharTok{+}
  
  \CommentTok{\# Set the colors as requested}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"Empty"} \OtherTok{=} \StringTok{"gold"}\NormalTok{, }\StringTok{"Not Empty"} \OtherTok{=} \StringTok{"dodgerblue"}\NormalTok{)) }\SpecialCharTok{+}
  
  \CommentTok{\# Improve readability}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.x =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{angle =} \DecValTok{45}\NormalTok{, }\AttributeTok{hjust =} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-7-1.pdf}}
- with no particular reason to take the conventional significance level
of 0.05, conclude that the vehicle year is still independent to the
emptiness of credit scores

\begin{itemize}
\tightlist
\item
  suggests that ppl with no credit score are not necessarily younger, so
  we assume that missing values are missing unintentionally
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{"TESTING FOR INDEPENDENCE OF ANNUAL\_MILEAGE EMPTINESS"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "TESTING FOR INDEPENDENCE OF ANNUAL_MILEAGE EMPTINESS"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{AM\_missing }\OtherTok{\textless{}{-}} \FunctionTok{is.na}\NormalTok{(train\_data}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE)}

\CommentTok{\# Get a list of all predictor variables to test, excluding ID and CREDIT\_SCORE itself}
\NormalTok{predictors\_to\_test }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}\FunctionTok{names}\NormalTok{(train\_data), }\FunctionTok{c}\NormalTok{(}\StringTok{"ID"}\NormalTok{, }\StringTok{"ANNUAL\_MILEAGE"}\NormalTok{))}

\CommentTok{\# Loop through each predictor and perform the appropriate test}
\ControlFlowTok{for}\NormalTok{ (var }\ControlFlowTok{in}\NormalTok{ predictors\_to\_test) \{}
  
  \CommentTok{\# Ignore any columns with no variation}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(train\_data[[var]])) }\SpecialCharTok{\textless{}} \DecValTok{2}\NormalTok{) }\ControlFlowTok{next}
  
  \CommentTok{\# {-}{-}{-} Test for association with CONTINUOUS variables {-}{-}{-}}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.numeric}\NormalTok{(train\_data[[var]])) \{}
    \CommentTok{\# We use a t{-}test to see if the mean of the numeric variable is}
    \CommentTok{\# different between the \textquotesingle{}missing\textquotesingle{} and \textquotesingle{}present\textquotesingle{} groups.}
\NormalTok{    test\_result }\OtherTok{\textless{}{-}} \FunctionTok{t.test}\NormalTok{(train\_data[[var]] }\SpecialCharTok{\textasciitilde{}}\NormalTok{ AM\_missing)}
\NormalTok{    p\_value }\OtherTok{\textless{}{-}}\NormalTok{ test\_result}\SpecialCharTok{$}\NormalTok{p.value}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Variable: \%{-}20s | Test: T{-}test         | P{-}value: \%.4f}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, var, p\_value))}
    
  \CommentTok{\# {-}{-}{-} Test for association with CATEGORICAL variables {-}{-}{-}}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.factor}\NormalTok{(train\_data[[var]]) }\SpecialCharTok{||} \FunctionTok{is.character}\NormalTok{(train\_data[[var]])) \{}
    \CommentTok{\# We use a Chi{-}squared test for independence between two categorical variables.}
    \CommentTok{\# We add \textquotesingle{}simulate.p.value = TRUE\textquotesingle{} to handle cases with low expected counts.}
\NormalTok{    test\_result }\OtherTok{\textless{}{-}} \FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(train\_data[[var]], AM\_missing), }\AttributeTok{simulate.p.value =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{    p\_value }\OtherTok{\textless{}{-}}\NormalTok{ test\_result}\SpecialCharTok{$}\NormalTok{p.value}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"Variable: \%{-}20s | Test: Chi{-}squared    | P{-}value: \%.4f}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, var, p\_value))}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Variable: AGE                  | Test: Chi-squared    | P-value: 0.4203
## Variable: GENDER               | Test: Chi-squared    | P-value: 0.8166
## Variable: DRIVING_EXPERIENCE   | Test: Chi-squared    | P-value: 0.5192
## Variable: EDUCATION            | Test: Chi-squared    | P-value: 0.6092
## Variable: CREDIT_SCORE         | Test: T-test         | P-value: 0.3480
## Variable: VEHICLE_OWNERSHIP    | Test: T-test         | P-value: 0.5202
## Variable: VEHICLE_YEAR         | Test: Chi-squared    | P-value: 0.2689
## Variable: MARRIED              | Test: T-test         | P-value: 0.8048
## Variable: CHILDREN             | Test: T-test         | P-value: 0.4170
## Variable: VEHICLE_TYPE         | Test: Chi-squared    | P-value: 0.4728
## Variable: SPEEDING_VIOLATIONS  | Test: T-test         | P-value: 0.5506
## Variable: PAST_ACCIDENTS       | Test: T-test         | P-value: 0.0999
## Variable: OUTCOME              | Test: T-test         | P-value: 0.1960
## Variable: CLAIMS               | Test: T-test         | P-value: 0.1095
\end{verbatim}

\begin{itemize}
\item
  pvalues very high, so likely that annual\_mileage is left empty
  independently of other variables
\item
  assume from here on that missing values are missing unintentionally
\end{itemize}

\subsection{imputing missing values}\label{imputing-missing-values}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 1. Select all numeric columns from train and test sets}
\NormalTok{train\_numeric }\OtherTok{\textless{}{-}}\NormalTok{ train\_data\_x }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric))}
\NormalTok{test\_numeric  }\OtherTok{\textless{}{-}}\NormalTok{ test\_data\_x }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric))}

\CommentTok{\# 2. Build recipe: Impute ONLY ANNUAL\_MILEAGE and CREDIT\_SCORE, using all numeric predictors}
\NormalTok{rec }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train\_numeric) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{step\_impute\_knn}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"ANNUAL\_MILEAGE"}\NormalTok{, }\StringTok{"CREDIT\_SCORE"}\NormalTok{))}

\CommentTok{\# 3. Prep the recipe (fit on training data)}
\NormalTok{rec\_prep }\OtherTok{\textless{}{-}} \FunctionTok{prep}\NormalTok{(rec, }\AttributeTok{training =}\NormalTok{ train\_numeric)}

\CommentTok{\# 4. Impute the training and test sets}
\NormalTok{train\_imputed }\OtherTok{\textless{}{-}} \FunctionTok{bake}\NormalTok{(rec\_prep, }\AttributeTok{new\_data =}\NormalTok{ train\_numeric)}
\NormalTok{test\_imputed  }\OtherTok{\textless{}{-}} \FunctionTok{bake}\NormalTok{(rec\_prep, }\AttributeTok{new\_data =}\NormalTok{ test\_numeric)}

\CommentTok{\# The result: train\_imputed and test\_imputed contain all numeric columns,}
\CommentTok{\# with only ANNUAL\_MILEAGE and CREDIT\_SCORE imputed, using relationships with all numeric variables.}

\NormalTok{train\_data\_imputed }\OtherTok{\textless{}{-}}\NormalTok{ train\_data}
\NormalTok{train\_data\_imputed}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE }\OtherTok{\textless{}{-}}\NormalTok{ train\_imputed}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE}
\NormalTok{train\_data\_imputed}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE }\OtherTok{\textless{}{-}}\NormalTok{ train\_imputed}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE}

\NormalTok{test\_data\_imputed }\OtherTok{\textless{}{-}}\NormalTok{ test\_data}
\NormalTok{test\_data\_imputed}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE }\OtherTok{\textless{}{-}}\NormalTok{ test\_imputed}\SpecialCharTok{$}\NormalTok{ANNUAL\_MILEAGE}
\NormalTok{test\_data\_imputed}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE }\OtherTok{\textless{}{-}}\NormalTok{ test\_imputed}\SpecialCharTok{$}\NormalTok{CREDIT\_SCORE}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  used PCA between numeric variables to impute missing values
\item
  wasnt possible to use the same model to also impute test data
\item
  used knn imputation instead
\item
  doesnt account for categorical variable values!
\end{itemize}

\subsection{histogram of covariates}\label{histogram-of-covariates}

\begin{itemize}
\tightlist
\item
  supressed as it makes the knitted document untidy
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-1.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-2.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-3.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-4.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-5.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-6.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-7.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-8.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-9.pdf}}
  \pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-10-10.pdf}}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(train\_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        ID            AGE          GENDER     DRIVING_EXPERIENCE
##  Min.   :   125   16-25:1611   female:3993   0-9y  :2822       
##  1st Qu.:249025   26-39:2459   male  :4007   10-19y:2641       
##  Median :500664   40-64:2339                 20-29y:1688       
##  Mean   :499893   65+  :1591                 30y+  : 849       
##  3rd Qu.:753723                                                
##  Max.   :999976                                                
##                                                                
##        EDUCATION     CREDIT_SCORE     VEHICLE_OWNERSHIP      VEHICLE_YEAR 
##  high school:3335   Min.   :0.05336   Min.   :0.000     after 2015 :2416  
##  none       :1524   1st Qu.:0.41637   1st Qu.:0.000     before 2015:5584  
##  university :3141   Median :0.52456   Median :1.000                       
##                     Mean   :0.51528   Mean   :0.695                       
##                     3rd Qu.:0.61700   3rd Qu.:1.000                       
##                     Max.   :0.96082   Max.   :1.000                       
##                     NA's   :804                                           
##     MARRIED          CHILDREN      ANNUAL_MILEAGE      VEHICLE_TYPE 
##  Min.   :0.0000   Min.   :0.0000   Min.   : 3000   sedan     :7623  
##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:10000   sports car: 377  
##  Median :0.0000   Median :1.0000   Median :12000                    
##  Mean   :0.4951   Mean   :0.6871   Mean   :11723                    
##  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:14000                    
##  Max.   :1.0000   Max.   :1.0000   Max.   :22000                    
##                                    NA's   :773                      
##  SPEEDING_VIOLATIONS PAST_ACCIDENTS      OUTCOME           CLAIMS      
##  Min.   : 0.000      Min.   : 0.000   Min.   :0.0000   Min.   :     0  
##  1st Qu.: 0.000      1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:     0  
##  Median : 0.000      Median : 0.000   Median :0.0000   Median :     0  
##  Mean   : 1.484      Mean   : 1.055   Mean   :0.3167   Mean   :  2360  
##  3rd Qu.: 2.000      3rd Qu.: 2.000   3rd Qu.:1.0000   3rd Qu.:  1838  
##  Max.   :22.000      Max.   :15.000   Max.   :1.0000   Max.   :116328  
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num\_cols }\OtherTok{=}\NormalTok{ train\_data\_imputed }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select\_if}\NormalTok{(is.numeric)}
\NormalTok{cor\_matrix }\OtherTok{=} \FunctionTok{cor}\NormalTok{(num\_cols)}
\FunctionTok{corrplot}\NormalTok{(cor\_matrix, }\AttributeTok{type =} \StringTok{"lower"}\NormalTok{, }\AttributeTok{diag =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-12-1.pdf}}
- looks like annual mileage has a negative correlation with being
married / having children - ppl with speeding violations are much more
likely to have past accidents - surprisingly non vehicle owners have a
higher correlation with making claims

\section{investigation of claim
sizes}\label{investigation-of-claim-sizes}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-13-1.pdf}}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Looks like there are no cases where outcome = 1 and there is a
  claimsize of 0
\item
  suggests that claims sizes are always nonzero and zero claims should
  be accounted for within the counts distribution
\end{itemize}

\subsection{Extreme value analysis of
claimsizes}\label{extreme-value-analysis-of-claimsizes}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nonzerosizes }\OtherTok{\textless{}{-}}\NormalTok{ data[data}\SpecialCharTok{$}\NormalTok{OUTCOME}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{, }\StringTok{"CLAIMS"}\NormalTok{, drop }\OtherTok{=}\NormalTok{ T]}
\FunctionTok{quantile}\NormalTok{(nonzerosizes, }\FunctionTok{c}\NormalTok{(}\FloatTok{0.95}\NormalTok{,}\FloatTok{0.97}\NormalTok{, }\FloatTok{0.99}\NormalTok{, }\FloatTok{0.995}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      95%      97%      99%    99.5% 
## 23303.06 29080.47 42786.68 51570.25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mean excess plot}
\FunctionTok{mrlplot}\NormalTok{(nonzerosizes, }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{45000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-14-1.pdf}}

\begin{itemize}
\tightlist
\item
  Mean excess function is rising, clearly a heavy tailed distribution
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fitting GEV distribution}
\NormalTok{block\_size }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{blocks }\OtherTok{\textless{}{-}} \FunctionTok{ceiling}\NormalTok{(}\FunctionTok{seq\_along}\NormalTok{(nonzerosizes) }\SpecialCharTok{/}\NormalTok{ block\_size)}
\NormalTok{GEVdf }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(nonzerosizes, blocks)}
\NormalTok{block\_maxima\_df }\OtherTok{\textless{}{-}}\NormalTok{ GEVdf }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(blocks) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{max\_claim =} \FunctionTok{max}\NormalTok{(nonzerosizes) }
\NormalTok{  )}
\NormalTok{gev\_fit }\OtherTok{\textless{}{-}}\NormalTok{ extRemes}\SpecialCharTok{::}\FunctionTok{fevd}\NormalTok{(block\_maxima\_df}\SpecialCharTok{$}\NormalTok{max\_claim)}
\FunctionTok{summary}\NormalTok{(gev\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## extRemes::fevd(x = block_maxima_df$max_claim)
## 
## [1] "Estimation Method used: MLE"
## 
## 
##  Negative Log-Likelihood Value:  695.5335 
## 
## 
##  Estimated parameters:
##     location        scale        shape 
## 3.312419e+04 1.112776e+04 2.191021e-01 
## 
##  Standard Error Estimates:
##    location       scale       shape 
## 1591.904652 1247.447031    0.101009 
## 
##  Estimated parameter covariance matrix.
##               location         scale        shape
## location 2534160.42263  1.131005e+06 -50.31878400
## scale    1131004.89478  1.556124e+06  -6.45730616
## shape        -50.31878 -6.457306e+00   0.01020283
## 
##  AIC = 1397.067 
## 
##  BIC = 1403.496
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(gev\_fit)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-15-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Hypothesis test with H0: shape = 0}
\CommentTok{\# Assuming a normal distribution of the shape parameter estimator}
\NormalTok{shape.estimate }\OtherTok{\textless{}{-}} \FloatTok{0.219102}
\NormalTok{shape.stderr }\OtherTok{\textless{}{-}} \FloatTok{0.101009}

\FunctionTok{print}\NormalTok{(shape.estimate}\SpecialCharTok{/}\NormalTok{shape.stderr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.169133
\end{verbatim}

\begin{itemize}
\item
  clearly, the shape parameter is significantly different from 0, so we
  can reject the null hypothesis of an exponential tail. It is quite
  obvious that we have a frechet type distribution of the nonzero claim
  sizess
\item
  Suggests use of frechet family
\item
  Could use gamma or lognormal from the exponential family
\end{itemize}

\subsection{lognormal model}\label{lognormal-model}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# lognormal}
\CommentTok{\# lm is equivalent to fitting glm(., gaussian(link = identity))}
\NormalTok{lognormal\_claimsize\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_data\_imputed[train\_data\_imputed}\SpecialCharTok{$}\NormalTok{OUTCOME }\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{,] }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{OUTCOME)}
\FunctionTok{names}\NormalTok{(train\_data\_imputed)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "ID"                  "AGE"                 "GENDER"             
##  [4] "DRIVING_EXPERIENCE"  "EDUCATION"           "CREDIT_SCORE"       
##  [7] "VEHICLE_OWNERSHIP"   "VEHICLE_YEAR"        "MARRIED"            
## [10] "CHILDREN"            "ANNUAL_MILEAGE"      "VEHICLE_TYPE"       
## [13] "SPEEDING_VIOLATIONS" "PAST_ACCIDENTS"      "OUTCOME"            
## [16] "CLAIMS"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lognormal\_claimsize\_df}\SpecialCharTok{$}\NormalTok{CLAIMS }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(lognormal\_claimsize\_df}\SpecialCharTok{$}\NormalTok{CLAIMS)}

\CommentTok{\# base model no interactions}
\NormalTok{claimsize.}\FloatTok{0.}\NormalTok{lognormal }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(CLAIMS }\SpecialCharTok{\textasciitilde{}}\NormalTok{., }
                   \AttributeTok{data =}\NormalTok{ lognormal\_claimsize\_df)}


\FunctionTok{names}\NormalTok{(train\_data\_x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "ID"                  "AGE"                 "GENDER"             
##  [4] "DRIVING_EXPERIENCE"  "EDUCATION"           "CREDIT_SCORE"       
##  [7] "VEHICLE_OWNERSHIP"   "VEHICLE_YEAR"        "MARRIED"            
## [10] "CHILDREN"            "ANNUAL_MILEAGE"      "VEHICLE_TYPE"       
## [13] "SPEEDING_VIOLATIONS" "PAST_ACCIDENTS"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model with interactions}
\NormalTok{claimsize.}\FloatTok{1.}\NormalTok{lognormal }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(CLAIMS }\SpecialCharTok{\textasciitilde{}}\NormalTok{(AGE }\SpecialCharTok{+}\NormalTok{ GENDER }\SpecialCharTok{+}\NormalTok{ DRIVING\_EXPERIENCE }\SpecialCharTok{+}\NormalTok{ EDUCATION }\SpecialCharTok{+}
\NormalTok{                             CREDIT\_SCORE }\SpecialCharTok{+}\NormalTok{ VEHICLE\_OWNERSHIP }\SpecialCharTok{+}\NormalTok{ VEHICLE\_YEAR }\SpecialCharTok{+}
\NormalTok{                             MARRIED }\SpecialCharTok{+}\NormalTok{ CHILDREN }\SpecialCharTok{+}\NormalTok{ ANNUAL\_MILEAGE }\SpecialCharTok{+}
\NormalTok{                             VEHICLE\_TYPE }\SpecialCharTok{+}\NormalTok{ SPEEDING\_VIOLATIONS }\SpecialCharTok{+}\NormalTok{ PAST\_ACCIDENTS)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }
                   \AttributeTok{data =}\NormalTok{ lognormal\_claimsize\_df)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}FULL MODEL NO INTERACTION TERMS{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "---------------------FULL MODEL NO INTERACTION TERMS------------------------"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{lognormal);}\FunctionTok{plot}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{lognormal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = CLAIMS ~ ., data = lognormal_claimsize_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.2413 -0.6461  0.1103  0.7844  3.2424 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(>|t|)    
## (Intercept)               8.069e+00  2.061e-01  39.150  < 2e-16 ***
## ID                       -2.414e-08  8.025e-08  -0.301  0.76355    
## AGE26-39                  2.899e-03  7.042e-02   0.041  0.96716    
## AGE40-64                  1.707e-02  8.819e-02   0.194  0.84657    
## AGE65+                   -9.327e-02  1.220e-01  -0.764  0.44470    
## GENDERmale                3.992e-01  4.998e-02   7.986 2.10e-15 ***
## DRIVING_EXPERIENCE10-19y -5.834e-01  8.632e-02  -6.758 1.73e-11 ***
## DRIVING_EXPERIENCE20-29y -5.004e-01  1.748e-01  -2.863  0.00424 ** 
## DRIVING_EXPERIENCE30y+   -1.203e-01  3.363e-01  -0.358  0.72070    
## EDUCATIONnone            -5.531e-03  5.795e-02  -0.095  0.92397    
## EDUCATIONuniversity      -3.734e-02  6.044e-02  -0.618  0.53678    
## CREDIT_SCORE              2.333e-01  2.222e-01   1.050  0.29384    
## VEHICLE_OWNERSHIP         5.863e-02  5.046e-02   1.162  0.24542    
## VEHICLE_YEARbefore 2015  -1.502e-02  8.035e-02  -0.187  0.85168    
## MARRIED                  -6.217e-02  5.984e-02  -1.039  0.29891    
## CHILDREN                 -1.120e-02  5.505e-02  -0.203  0.83886    
## ANNUAL_MILEAGE            8.497e-06  1.066e-05   0.797  0.42545    
## VEHICLE_TYPEsports car    2.300e-01  1.089e-01   2.112  0.03477 *  
## SPEEDING_VIOLATIONS       5.875e-03  2.546e-02   0.231  0.81754    
## PAST_ACCIDENTS            2.089e-02  3.748e-02   0.557  0.57736    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.181 on 2514 degrees of freedom
## Multiple R-squared:  0.06563,    Adjusted R-squared:  0.05856 
## F-statistic: 9.293 on 19 and 2514 DF,  p-value: < 2.2e-16
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-18-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}WHITE TEST{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "----------------WHITE TEST-----------------------------"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{white\_test}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{lognormal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## White's test results
## 
## Null hypothesis: Homoskedasticity of the residuals
## Alternative hypothesis: Heteroskedasticity of the residuals
## Test Statistic: 0.45
## P-value: 0.797812
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}VIF{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "-----------------VIF----------------------------"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{lognormal, }\AttributeTok{type =} \StringTok{"predictor"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## GVIFs computed for predictors
\end{verbatim}

\begin{verbatim}
##                         GVIF Df GVIF^(1/(2*Df)) Interacts With
## ID                  1.005306  1        1.002650           --  
## AGE                 3.033224  3        1.203143           --  
## GENDER              1.102305  1        1.049907           --  
## DRIVING_EXPERIENCE  4.569123  3        1.288167           --  
## EDUCATION           1.284516  2        1.064596           --  
## CREDIT_SCORE        1.491735  1        1.221366           --  
## VEHICLE_OWNERSHIP   1.135285  1        1.065498           --  
## VEHICLE_YEAR        1.068256  1        1.033565           --  
## MARRIED             1.365148  1        1.168396           --  
## CHILDREN            1.372683  1        1.171616           --  
## ANNUAL_MILEAGE      1.594910  1        1.262897           --  
## VEHICLE_TYPE        1.009676  1        1.004826           --  
## SPEEDING_VIOLATIONS 2.000328  1        1.414329           --  
## PAST_ACCIDENTS      1.657310  1        1.287366           --  
##                                                                                                                                                                                    Other Predictors
## ID                  AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## AGE                  ID, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## GENDER                  ID, AGE, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## DRIVING_EXPERIENCE                  ID, AGE, GENDER, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## EDUCATION                  ID, AGE, GENDER, DRIVING_EXPERIENCE, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## CREDIT_SCORE                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## VEHICLE_OWNERSHIP                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## VEHICLE_YEAR                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## MARRIED                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## CHILDREN                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## ANNUAL_MILEAGE                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, VEHICLE_TYPE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## VEHICLE_TYPE                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, SPEEDING_VIOLATIONS, PAST_ACCIDENTS
## SPEEDING_VIOLATIONS                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, PAST_ACCIDENTS
## PAST_ACCIDENTS                  ID, AGE, GENDER, DRIVING_EXPERIENCE, EDUCATION, CREDIT_SCORE, VEHICLE_OWNERSHIP, VEHICLE_YEAR, MARRIED, CHILDREN, ANNUAL_MILEAGE, VEHICLE_TYPE, SPEEDING_VIOLATIONS
\end{verbatim}

\begin{itemize}
\tightlist
\item
  good fit around the middle, but the fit near the tails suffer
\item
  doesnt seem heteroskedastic, linear model is appropriate in that
  regards
\item
  introducing interaction terms increases adj Rsq
\item
  not much multicollinearity between variables w no interaction terms
\end{itemize}

\subsubsection{Variable selection}\label{variable-selection}

\begin{itemize}
\tightlist
\item
  only investigate adjr2 due to the size of the predictorspace
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# forward selection}
\CommentTok{\# not running because it takes too long to knit}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}FORWARD{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\NormalTok{lognormal\_fwdselection }\OtherTok{\textless{}{-}} \FunctionTok{ols\_step\_forward\_adj\_r2}\NormalTok{(claimsize.}\FloatTok{1.}\NormalTok{lognormal)}
\NormalTok{lognormal\_fwdselection}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# backward selection}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}backward{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "----------------------backward----------------------"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}adjr2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "adjr2"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lognormal\_bwdselection }\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{::}\FunctionTok{step}\NormalTok{(claimsize.}\FloatTok{1.}\NormalTok{lognormal, }\AttributeTok{direction =} \StringTok{"backward"}\NormalTok{, }\AttributeTok{trace =} \DecValTok{0}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(lognormal\_bwdselection)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = CLAIMS ~ GENDER + DRIVING_EXPERIENCE + EDUCATION + 
##     VEHICLE_OWNERSHIP + VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + 
##     VEHICLE_TYPE + SPEEDING_VIOLATIONS + GENDER:CHILDREN + GENDER:SPEEDING_VIOLATIONS + 
##     EDUCATION:ANNUAL_MILEAGE + VEHICLE_OWNERSHIP:VEHICLE_YEAR + 
##     VEHICLE_YEAR:MARRIED + CHILDREN:ANNUAL_MILEAGE + ANNUAL_MILEAGE:SPEEDING_VIOLATIONS, 
##     data = lognormal_claimsize_df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.2824 -0.6446  0.1127  0.7990  3.1821 
## 
## Coefficients:
##                                             Estimate Std. Error t value
## (Intercept)                                8.985e+00  2.733e-01  32.875
## GENDERmale                                 2.794e-01  7.020e-02   3.980
## DRIVING_EXPERIENCE10-19y                  -5.679e-01  6.927e-02  -8.198
## DRIVING_EXPERIENCE20-29y                  -4.499e-01  1.547e-01  -2.908
## DRIVING_EXPERIENCE30y+                    -9.899e-02  3.287e-01  -0.301
## EDUCATIONnone                             -6.055e-01  2.683e-01  -2.257
## EDUCATIONuniversity                        1.865e-02  2.595e-01   0.072
## VEHICLE_OWNERSHIP                         -2.356e-01  1.502e-01  -1.569
## VEHICLE_YEARbefore 2015                   -7.289e-02  1.182e-01  -0.617
## MARRIED                                    1.485e-01  1.539e-01   0.965
## CHILDREN                                  -9.208e-01  2.632e-01  -3.499
## ANNUAL_MILEAGE                            -4.430e-05  1.762e-05  -2.515
## VEHICLE_TYPEsports car                     2.277e-01  1.082e-01   2.105
## SPEEDING_VIOLATIONS                       -1.705e-01  8.576e-02  -1.988
## GENDERmale:CHILDREN                        1.633e-01  9.654e-02   1.691
## GENDERmale:SPEEDING_VIOLATIONS             7.766e-02  5.128e-02   1.514
## EDUCATIONnone:ANNUAL_MILEAGE               4.567e-05  2.056e-05   2.222
## EDUCATIONuniversity:ANNUAL_MILEAGE        -3.995e-06  2.047e-05  -0.195
## VEHICLE_OWNERSHIP:VEHICLE_YEARbefore 2015  3.365e-01  1.578e-01   2.132
## VEHICLE_YEARbefore 2015:MARRIED           -2.333e-01  1.608e-01  -1.452
## CHILDREN:ANNUAL_MILEAGE                    6.365e-05  1.962e-05   3.243
## ANNUAL_MILEAGE:SPEEDING_VIOLATIONS         1.140e-05  6.538e-06   1.743
##                                           Pr(>|t|)    
## (Intercept)                                < 2e-16 ***
## GENDERmale                                7.08e-05 ***
## DRIVING_EXPERIENCE10-19y                  3.86e-16 ***
## DRIVING_EXPERIENCE20-29y                  0.003664 ** 
## DRIVING_EXPERIENCE30y+                    0.763314    
## EDUCATIONnone                             0.024092 *  
## EDUCATIONuniversity                       0.942719    
## VEHICLE_OWNERSHIP                         0.116844    
## VEHICLE_YEARbefore 2015                   0.537372    
## MARRIED                                   0.334749    
## CHILDREN                                  0.000476 ***
## ANNUAL_MILEAGE                            0.011963 *  
## VEHICLE_TYPEsports car                    0.035401 *  
## SPEEDING_VIOLATIONS                       0.046959 *  
## GENDERmale:CHILDREN                       0.090965 .  
## GENDERmale:SPEEDING_VIOLATIONS            0.130076    
## EDUCATIONnone:ANNUAL_MILEAGE              0.026385 *  
## EDUCATIONuniversity:ANNUAL_MILEAGE        0.845321    
## VEHICLE_OWNERSHIP:VEHICLE_YEARbefore 2015 0.033100 *  
## VEHICLE_YEARbefore 2015:MARRIED           0.146762    
## CHILDREN:ANNUAL_MILEAGE                   0.001198 ** 
## ANNUAL_MILEAGE:SPEEDING_VIOLATIONS        0.081382 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.175 on 2512 degrees of freedom
## Multiple R-squared:  0.07705,    Adjusted R-squared:  0.06934 
## F-statistic: 9.986 on 21 and 2512 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{itemize}
\item
  improvement in adjusted R squared from full model
\item
  backward selection models have more variables but higher adjRsq
\item
  Select out of backward selection models for this
\item
  all seem to have same adj R sq and AIC, choose one with the lowest
  number of variables, i.e the model chosen by prioritising AIC
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# backward stepwaise}
\NormalTok{lognormal\_fwdselection}\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{::}\FunctionTok{step}\NormalTok{(claimsize.}\FloatTok{1.}\NormalTok{lognormal, }\AttributeTok{direction =} \StringTok{"forward"}\NormalTok{, }\AttributeTok{trace =} \DecValTok{0}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(lognormal\_fwdselection)}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  backward selected model is chosen as the reduced model due to the
  increased adjusted R squared and parsimony
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{claimsize.}\FloatTok{2.}\NormalTok{lognormal }\OtherTok{\textless{}{-}}\NormalTok{ lognormal\_bwdselection}
\end{Highlighting}
\end{Shaded}

\subsubsection{Significance test}\label{significance-test}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# between full model with all interaction terms and backward stepwise model}
\FunctionTok{anova}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal,claimsize.}\FloatTok{1.}\NormalTok{lognormal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: CLAIMS ~ GENDER + DRIVING_EXPERIENCE + EDUCATION + VEHICLE_OWNERSHIP + 
##     VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + VEHICLE_TYPE + 
##     SPEEDING_VIOLATIONS + GENDER:CHILDREN + GENDER:SPEEDING_VIOLATIONS + 
##     EDUCATION:ANNUAL_MILEAGE + VEHICLE_OWNERSHIP:VEHICLE_YEAR + 
##     VEHICLE_YEAR:MARRIED + CHILDREN:ANNUAL_MILEAGE + ANNUAL_MILEAGE:SPEEDING_VIOLATIONS
## Model 2: CLAIMS ~ (AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION + CREDIT_SCORE + 
##     VEHICLE_OWNERSHIP + VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + 
##     VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2
##   Res.Df    RSS  Df Sum of Sq      F Pr(>F)
## 1   2512 3465.6                            
## 2   2379 3338.8 133    126.87 0.6797 0.9979
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Clearly, the dropped variables were not that significant
\end{itemize}

\subsubsection{Residual analysis}\label{residual-analysis}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot of type 1 standardised residuals}
\FunctionTok{hist}\NormalTok{(}\FunctionTok{summary}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal)}\SpecialCharTok{$}\NormalTok{res}\SpecialCharTok{/} \FunctionTok{summary}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal)}\SpecialCharTok{$}\NormalTok{sigma, }\AttributeTok{breaks =} \DecValTok{100}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"histogram of standardised residuals"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"standardised residuals"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-24-1.pdf}}
- looks left skewed, suggests havent taken account of patterns in the
data, possibly due to poor treatment of tail

\subsection{Gamma model}\label{gamma-model}

\begin{itemize}
\tightlist
\item
  consider common interaction terms and interaction terms suggested by
  correlation analysis
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{claimsize\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_data\_imputed[train\_data\_imputed}\SpecialCharTok{$}\NormalTok{OUTCOME }\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{,] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{OUTCOME)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# base model no interaction}
\NormalTok{claimsize.}\FloatTok{0.}\NormalTok{gamma }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(CLAIMS }\SpecialCharTok{\textasciitilde{}}\NormalTok{. , }\AttributeTok{family =} \FunctionTok{Gamma}\NormalTok{(}\AttributeTok{link =} \StringTok{"log"}\NormalTok{),}
                   \AttributeTok{data =}\NormalTok{ claimsize\_df)}

\CommentTok{\# w interactions}
\NormalTok{claimsize.}\FloatTok{1.}\NormalTok{gamma }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(CLAIMS }\SpecialCharTok{\textasciitilde{}}\NormalTok{(AGE }\SpecialCharTok{+}\NormalTok{ GENDER }\SpecialCharTok{+}\NormalTok{ DRIVING\_EXPERIENCE }\SpecialCharTok{+}\NormalTok{ EDUCATION }\SpecialCharTok{+}
\NormalTok{                             CREDIT\_SCORE }\SpecialCharTok{+}\NormalTok{ VEHICLE\_OWNERSHIP }\SpecialCharTok{+}\NormalTok{ VEHICLE\_YEAR }\SpecialCharTok{+}
\NormalTok{                             MARRIED }\SpecialCharTok{+}\NormalTok{ CHILDREN }\SpecialCharTok{+}\NormalTok{ ANNUAL\_MILEAGE }\SpecialCharTok{+}
\NormalTok{                             VEHICLE\_TYPE }\SpecialCharTok{+}\NormalTok{ SPEEDING\_VIOLATIONS }\SpecialCharTok{+}\NormalTok{ PAST\_ACCIDENTS)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{family =} \FunctionTok{Gamma}\NormalTok{(}\AttributeTok{link =} \StringTok{"log"}\NormalTok{),}
                   \AttributeTok{data =}\NormalTok{ claimsize\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: glm.fit: algorithm did not converge
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}FULL MODEL NO INTERACTION TERMS{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "---------------------FULL MODEL NO INTERACTION TERMS------------------------"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{gamma);}\FunctionTok{plot}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{gamma)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = CLAIMS ~ ., family = Gamma(link = "log"), data = claimsize_df)
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(>|t|)    
## (Intercept)               8.555e+00  1.944e-01  44.012  < 2e-16 ***
## ID                       -2.713e-08  7.568e-08  -0.358 0.720044    
## AGE26-39                 -7.097e-02  6.641e-02  -1.069 0.285391    
## AGE40-64                 -5.188e-02  8.318e-02  -0.624 0.532879    
## AGE65+                   -1.822e-01  1.151e-01  -1.583 0.113531    
## GENDERmale                4.028e-01  4.714e-02   8.544  < 2e-16 ***
## DRIVING_EXPERIENCE10-19y -5.776e-01  8.141e-02  -7.095 1.68e-12 ***
## DRIVING_EXPERIENCE20-29y -5.457e-01  1.649e-01  -3.310 0.000946 ***
## DRIVING_EXPERIENCE30y+   -1.892e-01  3.172e-01  -0.597 0.550841    
## EDUCATIONnone            -7.026e-04  5.466e-02  -0.013 0.989745    
## EDUCATIONuniversity      -1.457e-02  5.700e-02  -0.256 0.798212    
## CREDIT_SCORE              3.253e-01  2.095e-01   1.553 0.120622    
## VEHICLE_OWNERSHIP        -2.409e-03  4.759e-02  -0.051 0.959626    
## VEHICLE_YEARbefore 2015   8.060e-02  7.578e-02   1.064 0.287580    
## MARRIED                  -2.411e-02  5.644e-02  -0.427 0.669320    
## CHILDREN                  6.204e-03  5.192e-02   0.119 0.904892    
## ANNUAL_MILEAGE            5.129e-06  1.005e-05   0.510 0.610004    
## VEHICLE_TYPEsports car    2.353e-01  1.027e-01   2.291 0.022035 *  
## SPEEDING_VIOLATIONS       2.758e-02  2.402e-02   1.148 0.250901    
## PAST_ACCIDENTS           -2.947e-03  3.535e-02  -0.083 0.933551    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for Gamma family taken to be 1.241379)
## 
##     Null deviance: 2963.2  on 2533  degrees of freedom
## Residual deviance: 2724.3  on 2514  degrees of freedom
## AIC: 50079
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-26-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}WHITE TEST{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "----------------WHITE TEST-----------------------------"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{white\_test}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{gamma)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## White's test results
## 
## Null hypothesis: Homoskedasticity of the residuals
## Alternative hypothesis: Heteroskedasticity of the residuals
## Test Statistic: 1
## P-value: 0.605183
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\StringTok{\textquotesingle{}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}VIF{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "-----------------VIF----------------------------"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(claimsize.}\FloatTok{0.}\NormalTok{gamma, }\AttributeTok{type =} \StringTok{"predictor"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in vif.lm(claimsize.0.gamma, type = "predictor"): type = 'predictor' is available only for unweighted linear models;
##   type = 'terms' will be used
\end{verbatim}

\begin{verbatim}
##                         GVIF Df GVIF^(1/(2*Df))
## ID                  1.005306  1        1.002650
## AGE                 3.033224  3        1.203143
## GENDER              1.102305  1        1.049907
## DRIVING_EXPERIENCE  4.569123  3        1.288167
## EDUCATION           1.284516  2        1.064596
## CREDIT_SCORE        1.491735  1        1.221366
## VEHICLE_OWNERSHIP   1.135285  1        1.065498
## VEHICLE_YEAR        1.068256  1        1.033565
## MARRIED             1.365148  1        1.168396
## CHILDREN            1.372683  1        1.171616
## ANNUAL_MILEAGE      1.594910  1        1.262897
## VEHICLE_TYPE        1.009676  1        1.004826
## SPEEDING_VIOLATIONS 2.000328  1        1.414329
## PAST_ACCIDENTS      1.657310  1        1.287366
\end{verbatim}

\subsubsection{Variable selection}\label{variable-selection-1}

\begin{verbatim}
## 
## Call:
## glm(formula = CLAIMS ~ GENDER + DRIVING_EXPERIENCE + CREDIT_SCORE + 
##     VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + VEHICLE_TYPE + 
##     SPEEDING_VIOLATIONS + PAST_ACCIDENTS + GENDER:CHILDREN + 
##     CHILDREN:ANNUAL_MILEAGE + CREDIT_SCORE:PAST_ACCIDENTS + VEHICLE_YEAR:MARRIED + 
##     GENDER:SPEEDING_VIOLATIONS + CREDIT_SCORE:VEHICLE_TYPE, family = Gamma(link = "log"), 
##     data = df, control = glm.control(maxit = 100))
## 
## Coefficients:
##                                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)                          8.764e+00  2.361e-01  37.126  < 2e-16 ***
## GENDERmale                           2.660e-01  6.497e-02   4.094 4.37e-05 ***
## DRIVING_EXPERIENCE10-19y            -5.953e-01  7.069e-02  -8.422  < 2e-16 ***
## DRIVING_EXPERIENCE20-29y            -5.480e-01  1.549e-01  -3.537 0.000412 ***
## DRIVING_EXPERIENCE30y+              -1.502e-01  3.088e-01  -0.486 0.626840    
## CREDIT_SCORE                         4.418e-01  1.950e-01   2.266 0.023558 *  
## VEHICLE_YEARbefore 2015              2.311e-01  9.350e-02   2.472 0.013510 *  
## MARRIED                              2.449e-01  1.430e-01   1.713 0.086869 .  
## CHILDREN                            -7.110e-01  2.434e-01  -2.921 0.003518 ** 
## ANNUAL_MILEAGE                      -2.069e-05  1.366e-05  -1.515 0.129961    
## VEHICLE_TYPEsports car               7.186e-01  3.624e-01   1.983 0.047499 *  
## SPEEDING_VIOLATIONS                 -4.699e-02  4.963e-02  -0.947 0.343826    
## PAST_ACCIDENTS                       1.749e-01  1.134e-01   1.543 0.123067    
## GENDERmale:CHILDREN                  2.082e-01  8.995e-02   2.315 0.020709 *  
## CHILDREN:ANNUAL_MILEAGE              4.511e-05  1.809e-05   2.494 0.012702 *  
## CREDIT_SCORE:PAST_ACCIDENTS         -4.260e-01  2.275e-01  -1.872 0.061255 .  
## VEHICLE_YEARbefore 2015:MARRIED     -3.099e-01  1.493e-01  -2.076 0.037983 *  
## GENDERmale:SPEEDING_VIOLATIONS       8.845e-02  4.833e-02   1.830 0.067357 .  
## CREDIT_SCORE:VEHICLE_TYPEsports car -1.067e+00  7.690e-01  -1.387 0.165605    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for Gamma family taken to be 1.202638)
## 
##     Null deviance: 2963.2  on 2533  degrees of freedom
## Residual deviance: 2695.0  on 2515  degrees of freedom
## AIC: 50045
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{verbatim}
## 
## 
## --- Generating Diagnostic Plots for Final Model ---
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-28-1.pdf}}

\begin{verbatim}
##                         (Intercept)                          GENDERmale 
##                        6401.5457825                           1.3047019 
##            DRIVING_EXPERIENCE10-19y            DRIVING_EXPERIENCE20-29y 
##                           0.5513907                           0.5781134 
##              DRIVING_EXPERIENCE30y+                        CREDIT_SCORE 
##                           0.8605605                           1.5555631 
##             VEHICLE_YEARbefore 2015                             MARRIED 
##                           1.2599878                           1.2775392 
##                            CHILDREN                      ANNUAL_MILEAGE 
##                           0.4911376                           0.9999793 
##              VEHICLE_TYPEsports car                 SPEEDING_VIOLATIONS 
##                           2.0516241                           0.9540989 
##                      PAST_ACCIDENTS                 GENDERmale:CHILDREN 
##                           1.1911398                           1.2314638 
##             CHILDREN:ANNUAL_MILEAGE         CREDIT_SCORE:PAST_ACCIDENTS 
##                           1.0000451                           0.6531375 
##     VEHICLE_YEARbefore 2015:MARRIED      GENDERmale:SPEEDING_VIOLATIONS 
##                           0.7335132                           1.0924750 
## CREDIT_SCORE:VEHICLE_TYPEsports car 
##                           0.3442101
\end{verbatim}

\begin{verbatim}
## [1] "--------------------------------"
\end{verbatim}

\begin{verbatim}
##                                  GVIF Df GVIF^(1/(2*Df))
## GENDER                       2.160919  1        1.470006
## DRIVING_EXPERIENCE           2.832738  3        1.189509
## CREDIT_SCORE                 1.333893  1        1.154943
## VEHICLE_YEAR                 1.678581  1        1.295601
## MARRIED                      9.047066  1        3.007834
## CHILDREN                    31.138872  1        5.580221
## ANNUAL_MILEAGE               3.038172  1        1.743035
## VEHICLE_TYPE                12.979648  1        3.602728
## SPEEDING_VIOLATIONS          8.816592  1        2.969275
## PAST_ACCIDENTS              17.606395  1        4.195998
## GENDER:CHILDREN              3.670345  1        1.915814
## CHILDREN:ANNUAL_MILEAGE     24.160274  1        4.915310
## CREDIT_SCORE:PAST_ACCIDENTS 17.465245  1        4.179144
## VEHICLE_YEAR:MARRIED         9.025613  1        3.004266
## GENDER:SPEEDING_VIOLATIONS   7.373019  1        2.715330
## CREDIT_SCORE:VEHICLE_TYPE   13.055910  1        3.613296
\end{verbatim}

\begin{itemize}
\tightlist
\item
  high vif because we have interaction terms now
\item
  we opt to keep CHILDREN despite the high vif due to the pirnciple of
  hierarchy, to ensure model interpretation as otherwise interpretation
  becomes difficult
\end{itemize}

\paragraph{likelihood ratio tests}\label{likelihood-ratio-tests}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# between full model and stepwise selected}
\FunctionTok{anova}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma, claimsize.}\FloatTok{1.}\NormalTok{gamma, }\AttributeTok{test =} \StringTok{"LRT"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: CLAIMS ~ GENDER + DRIVING_EXPERIENCE + CREDIT_SCORE + VEHICLE_YEAR + 
##     MARRIED + CHILDREN + ANNUAL_MILEAGE + VEHICLE_TYPE + SPEEDING_VIOLATIONS + 
##     PAST_ACCIDENTS + GENDER:CHILDREN + CHILDREN:ANNUAL_MILEAGE + 
##     CREDIT_SCORE:PAST_ACCIDENTS + VEHICLE_YEAR:MARRIED + GENDER:SPEEDING_VIOLATIONS + 
##     CREDIT_SCORE:VEHICLE_TYPE
## Model 2: CLAIMS ~ (AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION + CREDIT_SCORE + 
##     VEHICLE_OWNERSHIP + VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + 
##     VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2
##   Resid. Df Resid. Dev  Df Deviance Pr(>Chi)
## 1      2515     2695.0                      
## 2      2379     2560.1 136    134.9   0.7544
\end{verbatim}

\begin{itemize}
\tightlist
\item
  removal of the interaction terms doesnt seem significant under H0,
  meaning the stepwise selected model is preferred.
\end{itemize}

\subsubsection{Residual analysis}\label{residual-analysis-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# histogram of type 1 standardised residuals}
\FunctionTok{hist}\NormalTok{(}\FunctionTok{rstandard}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma), }\AttributeTok{breaks =} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-30-1.pdf}}
- approximately centered around mean of zero, but still some skewness

\begin{itemize}
\tightlist
\item
  signs of heteroskedasticity as residuals are not uniform over fitted
  values
\end{itemize}

\subsubsection{identifying influential points (outliers, high
leverage)}\label{identifying-influential-points-outliers-high-leverage}

\begin{verbatim}
## [1] "cooks threshold is  0.0015785319652723"
\end{verbatim}

\begin{verbatim}
## # A tibble: 97 x 21
##        ID AGE   GENDER DRIVING_EXPERIENCE EDUCATION   CREDIT_SCORE
##     <dbl> <fct> <fct>  <fct>              <fct>              <dbl>
##  1 393748 16-25 female 0-9y               university         0.282
##  2 955572 26-39 male   10-19y             high school        0.290
##  3 943240 65+   female 30y+               university         0.596
##  4 167289 16-25 male   0-9y               none               0.337
##  5 991678 40-64 male   10-19y             high school        0.536
##  6  36193 26-39 female 10-19y             high school        0.604
##  7 959649 26-39 female 0-9y               high school        0.633
##  8 210243 16-25 male   0-9y               none               0.274
##  9 937825 40-64 female 0-9y               university         0.669
## 10  98177 26-39 male   10-19y             high school        0.459
## # i 87 more rows
## # i 15 more variables: VEHICLE_OWNERSHIP <dbl>, VEHICLE_YEAR <fct>,
## #   MARRIED <dbl>, CHILDREN <dbl>, ANNUAL_MILEAGE <dbl>, VEHICLE_TYPE <fct>,
## #   SPEEDING_VIOLATIONS <dbl>, PAST_ACCIDENTS <dbl>, CLAIMS <dbl>,
## #   .fitted <dbl>, .resid <dbl>, .hat <dbl>, .sigma <dbl>, .cooksd <dbl>,
## #   .std.resid <dbl>
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-1.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-2.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-3.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-4.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-5.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-6.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-7.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-8.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-9.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-10.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-11.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-12.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-13.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-14.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-15.pdf}}
\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-32-16.pdf}}

\begin{itemize}
\tightlist
\item
  There seems to be one case with an extremely high claim size (approx
  6x the next biggest), which is likely to be a major influential point
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plotting influential points}
\FunctionTok{ggplot}\NormalTok{(model\_diagnostics, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ .hat, }\AttributeTok{y =}\NormalTok{ .std.resid)) }\SpecialCharTok{+}
  \CommentTok{\# Points are sized by their Cook\textquotesingle{}s distance}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{size =}\NormalTok{ .cooksd), }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{shape =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  
  \CommentTok{\# Add a smoother to see the general trend}
  \FunctionTok{geom\_smooth}\NormalTok{(}\AttributeTok{se =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{col =} \StringTok{"dodgerblue"}\NormalTok{) }\SpecialCharTok{+}
  
  \CommentTok{\# Highlight the most influential points found earlier}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data =}\NormalTok{ influential\_points, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{size =}\NormalTok{ .cooksd), }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  
  \CommentTok{\# Add labels to the influential points (e.g., by row number)}
  \FunctionTok{geom\_text}\NormalTok{(}\AttributeTok{data =}\NormalTok{ influential\_points, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =} \FunctionTok{rownames}\NormalTok{(influential\_points)),}
            \AttributeTok{vjust =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\AttributeTok{color =} \StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  
  \CommentTok{\# Add a horizontal line at 0}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{, }\AttributeTok{color =} \StringTok{"gray50"}\NormalTok{) }\SpecialCharTok{+}
  
  \CommentTok{\# Add labels and a title}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Influence Plot: Residuals vs. Leverage"}\NormalTok{,}
    \AttributeTok{subtitle =} \StringTok{"Points sized by Cook\textquotesingle{}s Distance. Red points are highly influential."}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"Leverage (Hat Values)"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Standardized Deviance Residuals"}\NormalTok{,}
    \AttributeTok{size =} \StringTok{"Cook\textquotesingle{}s D"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = "cs")'
\end{verbatim}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-33-1.pdf}}
- opted for cooks distance as it combines the outlier and high leverage
status of points into one metric - 96 influential points

\paragraph{investigating how influential points affect our
model}\label{investigating-how-influential-points-affect-our-model}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{influential\_rows }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{rownames}\NormalTok{(influential\_points))}
\NormalTok{claimsize\_df\_no\_influencers }\OtherTok{\textless{}{-}}\NormalTok{ claimsize\_df[}\SpecialCharTok{{-}}\NormalTok{influential\_rows, ]}
\NormalTok{model\_without\_influencers }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(}\FunctionTok{formula}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma),}
                                 \AttributeTok{family =} \FunctionTok{Gamma}\NormalTok{(}\AttributeTok{link =} \StringTok{"log"}\NormalTok{),}
                                 \AttributeTok{data =}\NormalTok{ claimsize\_df\_no\_influencers)}


\NormalTok{comparison }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\AttributeTok{Original =} \FunctionTok{coef}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma),}
                    \AttributeTok{No\_Influencers =} \FunctionTok{coef}\NormalTok{(model\_without\_influencers))}

\FunctionTok{print}\NormalTok{(comparison)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                          Original No_Influencers
## (Intercept)                          8.764295e+00   8.733942e+00
## GENDERmale                           2.659746e-01   2.489130e-01
## DRIVING_EXPERIENCE10-19y            -5.953116e-01  -5.853716e-01
## DRIVING_EXPERIENCE20-29y            -5.479853e-01  -5.591693e-01
## DRIVING_EXPERIENCE30y+              -1.501714e-01  -2.972910e-01
## CREDIT_SCORE                         4.418376e-01   4.076653e-01
## VEHICLE_YEARbefore 2015              2.311020e-01   2.237383e-01
## MARRIED                              2.449357e-01   2.563357e-01
## CHILDREN                            -7.110310e-01  -6.863137e-01
## ANNUAL_MILEAGE                      -2.068753e-05  -1.630819e-05
## VEHICLE_TYPEsports car               7.186317e-01   7.650618e-01
## SPEEDING_VIOLATIONS                 -4.698791e-02  -4.791772e-02
## PAST_ACCIDENTS                       1.749107e-01   1.675351e-01
## GENDERmale:CHILDREN                  2.082036e-01   1.905174e-01
## CHILDREN:ANNUAL_MILEAGE              4.510647e-05   4.385865e-05
## CREDIT_SCORE:PAST_ACCIDENTS         -4.259676e-01  -3.929006e-01
## VEHICLE_YEARbefore 2015:MARRIED     -3.099096e-01  -3.109545e-01
## GENDERmale:SPEEDING_VIOLATIONS       8.844577e-02   9.291959e-02
## CREDIT_SCORE:VEHICLE_TYPEsports car -1.066503e+00  -1.187627e+00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\AttributeTok{Original\_Dispersion =} \FunctionTok{summary}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma)}\SpecialCharTok{$}\NormalTok{dispersion, }\AttributeTok{No\_Influencers\_Dispersion =} \FunctionTok{summary}\NormalTok{(model\_without\_influencers)}\SpecialCharTok{$}\NormalTok{dispersion)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Original_Dispersion No_Influencers_Dispersion 
##                  1.202638                  1.209761
\end{verbatim}

\begin{itemize}
\tightlist
\item
  not much difference in dispersion
\item
  influential points arent doing too much to significantly affect the
  model fit
\end{itemize}

\subsection{Testing the Gamma and Lognormal
model}\label{testing-the-gamma-and-lognormal-model}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Helper: coerce factor levels in newdata to training levels stored in the fit}
\NormalTok{prep\_newdata\_for }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(newdata, fit) \{}
\NormalTok{  nd }\OtherTok{\textless{}{-}}\NormalTok{ newdata}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{xlevels)) \{}
    \ControlFlowTok{for}\NormalTok{ (nm }\ControlFlowTok{in} \FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{xlevels)) \{}
      \ControlFlowTok{if}\NormalTok{ (nm }\SpecialCharTok{\%in\%} \FunctionTok{names}\NormalTok{(nd)) \{}
\NormalTok{        nd[[nm]] }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(nd[[nm]], }\AttributeTok{levels =}\NormalTok{ fit}\SpecialCharTok{$}\NormalTok{xlevels[[nm]])}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
  \FunctionTok{droplevels}\NormalTok{(nd)}
\NormalTok{\}}

\CommentTok{\# 1) Test set for severity evaluation (only positive claims)}
\NormalTok{test\_claimsize\_df }\OtherTok{\textless{}{-}}\NormalTok{ test\_data\_imputed }\SpecialCharTok{|\textgreater{}}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(CLAIMS }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)}



\CommentTok{\# 2) Align test data to each model}
\NormalTok{test\_for\_gamma    }\OtherTok{\textless{}{-}} \FunctionTok{prep\_newdata\_for}\NormalTok{(test\_claimsize\_df, claimsize.}\FloatTok{2.}\NormalTok{gamma)}
\NormalTok{test\_for\_lognorm  }\OtherTok{\textless{}{-}} \FunctionTok{prep\_newdata\_for}\NormalTok{(test\_claimsize\_df, claimsize.}\FloatTok{2.}\NormalTok{lognormal)}

\CommentTok{\# 3) Predictions}
\CommentTok{\# Gamma(log): already on the dollar scale}
\NormalTok{pred\_gamma }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma, }\AttributeTok{newdata =}\NormalTok{ test\_for\_gamma, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\CommentTok{\# Lognormal (lm on log(CLAIMS)): use smearing correction}
\NormalTok{pred\_log }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal, }\AttributeTok{newdata =}\NormalTok{ test\_for\_lognorm)  }\CommentTok{\# predicts log(CLAIMS)}

\CommentTok{\# Duans smearing factor from TRAINING residuals of the log model}
\NormalTok{sf }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{exp}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal)), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{pred\_lognormal }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(pred\_log) }\SpecialCharTok{*}\NormalTok{ sf}


\CommentTok{\# 4) Metrics}
\NormalTok{actual\_claims }\OtherTok{\textless{}{-}}\NormalTok{ test\_for\_lognorm}\SpecialCharTok{$}\NormalTok{CLAIMS}

\NormalTok{rmse }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(a, p) }\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{mean}\NormalTok{((a }\SpecialCharTok{{-}}\NormalTok{ p)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{mae  }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(a, p) }\FunctionTok{mean}\NormalTok{(}\FunctionTok{abs}\NormalTok{(a }\SpecialCharTok{{-}}\NormalTok{ p), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{rmse\_gamma }\OtherTok{\textless{}{-}} \FunctionTok{rmse}\NormalTok{(actual\_claims, pred\_gamma)}
\NormalTok{mae\_gamma  }\OtherTok{\textless{}{-}} \FunctionTok{mae}\NormalTok{(actual\_claims, pred\_gamma)}

\NormalTok{rmse\_lognormal }\OtherTok{\textless{}{-}} \FunctionTok{rmse}\NormalTok{(actual\_claims, pred\_lognormal)}
\NormalTok{mae\_lognormal  }\OtherTok{\textless{}{-}} \FunctionTok{mae}\NormalTok{(actual\_claims, pred\_lognormal)}

\NormalTok{comparison\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Model =} \FunctionTok{c}\NormalTok{(}\StringTok{"Gamma GLM"}\NormalTok{, }\StringTok{"Lognormal (lm + smearing)"}\NormalTok{),}
  \AttributeTok{RMSE  =} \FunctionTok{c}\NormalTok{(rmse\_gamma, rmse\_lognormal),}
  \AttributeTok{MAE   =} \FunctionTok{c}\NormalTok{(mae\_gamma,  mae\_lognormal)}
\NormalTok{)}
\FunctionTok{print}\NormalTok{(comparison\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                       Model     RMSE      MAE
## 1                 Gamma GLM 8950.423 5578.078
## 2 Lognormal (lm + smearing) 8970.584 5617.047
\end{verbatim}

When we fit a lognormal severity model (lm on log(CLAIMS)), the model
predicts the mean of the log outcome. Simply exponentiating those
predictions gives the conditional median on the dollar scale and
underestimates the mean (Jensen's inequality). To obtain unbiased mean
severities, we apply a backtransformation correction: Duan's smearing
factor (multiply by the average of exp(residuals)) or, under
homoskedastic normal logerrors, multiply by exp(sigma2/2). Gamma GLM
predictions (log link) already return the mean and need no correction.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot errors}

\FunctionTok{hist}\NormalTok{(pred\_gamma }\SpecialCharTok{{-}}\NormalTok{ actual\_claims, }\AttributeTok{breaks =} \DecValTok{100}\NormalTok{, }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{80000}\NormalTok{, }\DecValTok{40000}\NormalTok{),}
     \AttributeTok{main =} \StringTok{\textquotesingle{}gamma model errors\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-36-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(pred\_lognormal }\SpecialCharTok{{-}}\NormalTok{ actual\_claims, }\AttributeTok{breaks =} \DecValTok{100}\NormalTok{, }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{80000}\NormalTok{, }\DecValTok{40000}\NormalTok{),}
     \AttributeTok{main =} \StringTok{\textquotesingle{}lognormal model errors\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-36-2.pdf}}
- There are some extreme tail cases that our models mis, leading to a
skewed error distribution

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# computing average errors}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"gamma model"}\NormalTok{, }\FunctionTok{mean}\NormalTok{(pred\_gamma }\SpecialCharTok{{-}}\NormalTok{ actual\_claims)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "gamma model -2.47898757513912"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"lognormal model"}\NormalTok{, }\FunctionTok{mean}\NormalTok{(pred\_lognormal }\SpecialCharTok{{-}}\NormalTok{ actual\_claims)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "lognormal model -3.15019208632837"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# observing tail behaviours of the errors}
\NormalTok{gamma\_model\_errors }\OtherTok{\textless{}{-}}\NormalTok{ pred\_gamma }\SpecialCharTok{{-}}\NormalTok{ actual\_claims}
\NormalTok{gamma\_model\_errors\_tail }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(gamma\_model\_errors[gamma\_model\_errors  }\SpecialCharTok{\textless{}}\NormalTok{ (}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{)])}
\NormalTok{lognormal\_model\_errors }\OtherTok{\textless{}{-}}\NormalTok{ pred\_lognormal }\SpecialCharTok{{-}}\NormalTok{ actual\_claims}
\NormalTok{lognormal\_model\_errors\_tail }\OtherTok{\textless{}{-}} \FunctionTok{abs}\NormalTok{(lognormal\_model\_errors[lognormal\_model\_errors  }\SpecialCharTok{\textless{}}\NormalTok{ (}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# {-}{-}{-} 1. Define Your Data and Names {-}{-}{-}}
\CommentTok{\# Replace these placeholder vectors with your actual data}
\NormalTok{vector1 }\OtherTok{\textless{}{-}}\NormalTok{ gamma\_model\_errors\_tail }\CommentTok{\# e.g., errors\_gamma}
\NormalTok{vector2 }\OtherTok{\textless{}{-}}\NormalTok{ lognormal\_model\_errors\_tail   }\CommentTok{\# e.g., errors\_lognormal}

\CommentTok{\# Define names for the legend}
\NormalTok{name1 }\OtherTok{\textless{}{-}} \StringTok{"Gamma Model Errors"}
\NormalTok{name2 }\OtherTok{\textless{}{-}} \StringTok{"Lognormal Model Errors"}




\CommentTok{\# {-}{-}{-} Plot 1: Log{-}Log Survival Plot {-}{-}{-}}

\NormalTok{ecdf\_x }\OtherTok{\textless{}{-}} \FunctionTok{ecdf}\NormalTok{(vector1)}
\NormalTok{data\_x }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{val =} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(vector1))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{prob =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{ecdf\_x}\NormalTok{(val)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(prob }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)}
\NormalTok{ecdf\_y }\OtherTok{\textless{}{-}} \FunctionTok{ecdf}\NormalTok{(vector2)}
\NormalTok{data\_y }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{val =} \FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(vector2))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}\AttributeTok{prob =} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{ecdf\_y}\NormalTok{(val)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(prob }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)}
\NormalTok{xlim\_range }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(}\FunctionTok{c}\NormalTok{(data\_x}\SpecialCharTok{$}\NormalTok{val, data\_y}\SpecialCharTok{$}\NormalTok{val))}
\NormalTok{ylim\_range }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(}\FunctionTok{c}\NormalTok{(data\_x}\SpecialCharTok{$}\NormalTok{prob, data\_y}\SpecialCharTok{$}\NormalTok{prob))}
\FunctionTok{plot}\NormalTok{(data\_x}\SpecialCharTok{$}\NormalTok{val, data\_x}\SpecialCharTok{$}\NormalTok{prob, }\AttributeTok{type =} \StringTok{"p"}\NormalTok{, }\AttributeTok{log =} \StringTok{"xy"}\NormalTok{, }\AttributeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{xlim =}\NormalTok{ xlim\_range, }\AttributeTok{ylim =}\NormalTok{ ylim\_range, }\AttributeTok{main =} \StringTok{"Log{-}Log Survival Plot"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Value (log scale)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"P(Value \textgreater{} x) (log scale)"}\NormalTok{)}
\FunctionTok{points}\NormalTok{(data\_y}\SpecialCharTok{$}\NormalTok{val, data\_y}\SpecialCharTok{$}\NormalTok{prob, }\AttributeTok{col =} \StringTok{"firebrick"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"bottomleft"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(name1, name2), }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"dodgerblue"}\NormalTok{, }\StringTok{"firebrick"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{bty =} \StringTok{"n"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-39-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# {-}{-}{-} Plot 2: Mean Excess Plot {-}{-}{-}}

\NormalTok{mean\_excess\_func }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data) \{}
\NormalTok{  thresholds }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(}\FunctionTok{sort}\NormalTok{(data))}
\NormalTok{  excess }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(thresholds, }\ControlFlowTok{function}\NormalTok{(u) \{ }\FunctionTok{mean}\NormalTok{(data[data }\SpecialCharTok{\textgreater{}}\NormalTok{ u] }\SpecialCharTok{{-}}\NormalTok{ u) \})}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{threshold =}\NormalTok{ thresholds, }\AttributeTok{mean\_excess =}\NormalTok{ excess))}
\NormalTok{\}}
\NormalTok{me\_x }\OtherTok{\textless{}{-}} \FunctionTok{mean\_excess\_func}\NormalTok{(vector1)}
\NormalTok{me\_y }\OtherTok{\textless{}{-}} \FunctionTok{mean\_excess\_func}\NormalTok{(vector2)}
\NormalTok{xlim\_range\_me }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(}\FunctionTok{c}\NormalTok{(me\_x}\SpecialCharTok{$}\NormalTok{threshold, me\_y}\SpecialCharTok{$}\NormalTok{threshold))}
\NormalTok{ylim\_range\_me }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(}\FunctionTok{c}\NormalTok{(me\_x}\SpecialCharTok{$}\NormalTok{mean\_excess, me\_y}\SpecialCharTok{$}\NormalTok{mean\_excess), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(me\_x}\SpecialCharTok{$}\NormalTok{threshold, me\_x}\SpecialCharTok{$}\NormalTok{mean\_excess, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{col =} \StringTok{"dodgerblue"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{20000}\NormalTok{), }\AttributeTok{ylim =}\NormalTok{ ylim\_range\_me, }\AttributeTok{main =} \StringTok{"Mean Excess Plot"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Threshold (u)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Mean Excess over Threshold e(u)"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(me\_y}\SpecialCharTok{$}\NormalTok{threshold, me\_y}\SpecialCharTok{$}\NormalTok{mean\_excess, }\AttributeTok{col =} \StringTok{"firebrick"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{c}\NormalTok{(name1, name2), }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{"dodgerblue"}\NormalTok{, }\StringTok{"firebrick"}\NormalTok{), }\AttributeTok{lty =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{bty =} \StringTok{"n"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-39-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# AIC for the Gamma(GLM) model (already on Y{-}scale)}
\NormalTok{aic\_gamma }\OtherTok{\textless{}{-}} \FunctionTok{AIC}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma)}

\CommentTok{\# AIC for the lognormal model from lm(log(CLAIMS) \textasciitilde{} ...)}
\CommentTok{\# Convert the lm to a lognormal likelihood on Y}
\NormalTok{mf\_ln  }\OtherTok{\textless{}{-}} \FunctionTok{model.frame}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal)}
\NormalTok{y\_log  }\OtherTok{\textless{}{-}} \FunctionTok{model.response}\NormalTok{(mf\_ln)               }\CommentTok{\# = log(CLAIMS)}
\NormalTok{y      }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(y\_log)                          }\CommentTok{\# original scale}
\NormalTok{mu\_log }\OtherTok{\textless{}{-}} \FunctionTok{fitted}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal)       }\CommentTok{\# mean on log scale}
\NormalTok{sdlog  }\OtherTok{\textless{}{-}} \FunctionTok{sigma}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal)        }\CommentTok{\# residual SD on log scale}

\NormalTok{ll\_lognorm }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{dlnorm}\NormalTok{(y, }\AttributeTok{meanlog =}\NormalTok{ mu\_log, }\AttributeTok{sdlog =}\NormalTok{ sdlog, }\AttributeTok{log =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{k\_lognorm  }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(}\FunctionTok{coef}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{lognormal)) }\SpecialCharTok{+} \DecValTok{1}  \CommentTok{\# +1 for sd}
\NormalTok{aic\_lognorm }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ ll\_lognorm }\SpecialCharTok{+} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ k\_lognorm}

\CommentTok{\# (Equivalent shortcut: aic\_lognorm \textless{}{-} AIC(claimsize.2.lognormal) + 2 * sum(log(y)))}

\CommentTok{\# Compare}
\NormalTok{aics }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{Gamma =}\NormalTok{ aic\_gamma, }\AttributeTok{Lognormal =}\NormalTok{ aic\_lognorm)}
\NormalTok{delta }\OtherTok{\textless{}{-}}\NormalTok{ aics }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(aics)}
\NormalTok{akaike\_wt }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ delta) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ delta))}

\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Model =} \FunctionTok{names}\NormalTok{(aics), }\AttributeTok{AIC =}\NormalTok{ aics, }\AttributeTok{DeltaAIC =}\NormalTok{ delta, }\AttributeTok{AkaikeWeight =}\NormalTok{ akaike\_wt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               Model      AIC DeltaAIC AkaikeWeight
## Gamma         Gamma 50045.40   0.0000 1.000000e+00
## Lognormal Lognormal 50253.18 207.7781 7.612986e-46
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# QQ Plot against Exponential (for tail diagnosis)}
\NormalTok{qqtail }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(vec, col, }\AttributeTok{add=}\ConstantTok{FALSE}\NormalTok{, ...) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(vec)}
\NormalTok{  sorted }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(vec)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{floor}\NormalTok{(}\FloatTok{0.1} \SpecialCharTok{*}\NormalTok{ n)}
\NormalTok{  tail }\OtherTok{\textless{}{-}}\NormalTok{ sorted[(n}\SpecialCharTok{{-}}\NormalTok{k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\NormalTok{n]}
\NormalTok{  qexp }\OtherTok{\textless{}{-}} \FunctionTok{qexp}\NormalTok{(}\FunctionTok{ppoints}\NormalTok{(k), }\AttributeTok{rate=}\DecValTok{1}\SpecialCharTok{/}\FunctionTok{mean}\NormalTok{(tail }\SpecialCharTok{{-}} \FunctionTok{min}\NormalTok{(tail)))}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{add) \{}
    \FunctionTok{plot}\NormalTok{(qexp, tail, }\AttributeTok{col=}\NormalTok{col, }\AttributeTok{pch=}\DecValTok{16}\NormalTok{, }\AttributeTok{xlab=}\StringTok{"Theoretical Quantiles (Exp)"}\NormalTok{, }
         \AttributeTok{ylab=}\StringTok{"Sample Quantiles"}\NormalTok{, }\AttributeTok{main=}\StringTok{"QQ Plot (Tail)"}\NormalTok{, ...)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{points}\NormalTok{(qexp, tail, }\AttributeTok{col=}\NormalTok{col, }\AttributeTok{pch=}\DecValTok{16}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}

\FunctionTok{qqtail}\NormalTok{(gamma\_model\_errors\_tail, }\StringTok{"blue"}\NormalTok{)}
\FunctionTok{qqtail}\NormalTok{(lognormal\_model\_errors\_tail, }\StringTok{"red"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"Gamma errors"}\NormalTok{, }\StringTok{"Lognormal errors"}\NormalTok{), }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\AttributeTok{pch=}\DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-41-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Hill Plot (Pareto tail index estimator)}
\NormalTok{hillplot }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(vec, col, }\AttributeTok{add=}\ConstantTok{FALSE}\NormalTok{, ...) \{}
\NormalTok{  sorted }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(vec, }\AttributeTok{decreasing=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(vec)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \DecValTok{2}\SpecialCharTok{:}\NormalTok{(n}\DecValTok{{-}1}\NormalTok{)}
\NormalTok{  hill }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(k, }\ControlFlowTok{function}\NormalTok{(i) }\FunctionTok{mean}\NormalTok{(}\FunctionTok{log}\NormalTok{(sorted[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{i])) }\SpecialCharTok{{-}} \FunctionTok{log}\NormalTok{(sorted[i]))}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{add) \{}
    \FunctionTok{plot}\NormalTok{(k, hill, }\AttributeTok{type=}\StringTok{"l"}\NormalTok{, }\AttributeTok{col=}\NormalTok{col, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}
         \AttributeTok{xlab=}\StringTok{"Order Statistics k"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Hill Estimator"}\NormalTok{, }\AttributeTok{main=}\StringTok{"Hill Plot"}\NormalTok{, ...)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{lines}\NormalTok{(k, hill, }\AttributeTok{col=}\NormalTok{col, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}

\FunctionTok{hillplot}\NormalTok{(gamma\_model\_errors\_tail, }\StringTok{"blue"}\NormalTok{)}
\FunctionTok{hillplot}\NormalTok{(lognormal\_model\_errors\_tail, }\StringTok{"red"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"Gamma errors"}\NormalTok{, }\StringTok{"Lognormal errors"}\NormalTok{), }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-41-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Maximum{-}to{-}Sum Plot (finite moments check)}
\NormalTok{max2sumplot }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(vec, col, }\AttributeTok{add=}\ConstantTok{FALSE}\NormalTok{, ...) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(vec)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n}
\NormalTok{  maxvals }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(k, }\ControlFlowTok{function}\NormalTok{(i) }\FunctionTok{max}\NormalTok{(vec[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{i]))}
\NormalTok{  sumvals }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(k, }\ControlFlowTok{function}\NormalTok{(i) }\FunctionTok{sum}\NormalTok{(vec[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{i]))}
\NormalTok{  ratio }\OtherTok{\textless{}{-}}\NormalTok{ maxvals}\SpecialCharTok{/}\NormalTok{sumvals}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\NormalTok{add) \{}
    \FunctionTok{plot}\NormalTok{(k, ratio, }\AttributeTok{type=}\StringTok{"l"}\NormalTok{, }\AttributeTok{col=}\NormalTok{col, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}
         \AttributeTok{xlab=}\StringTok{"Sample Size"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Max/Sum"}\NormalTok{, }\AttributeTok{main=}\StringTok{"Maximum{-}to{-}Sum Plot"}\NormalTok{, ...)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{lines}\NormalTok{(k, ratio, }\AttributeTok{col=}\NormalTok{col, }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}

\FunctionTok{max2sumplot}\NormalTok{(gamma\_model\_errors\_tail, }\StringTok{"blue"}\NormalTok{)}
\FunctionTok{max2sumplot}\NormalTok{(lognormal\_model\_errors\_tail, }\StringTok{"red"}\NormalTok{, }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"Gamma errors"}\NormalTok{, }\StringTok{"Lognormal errors"}\NormalTok{), }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-41-3.pdf}}

\begin{itemize}
\item
  Not much difference in the tail, however we choose Gamma model largely
  due to the difference in AIC.
\item
  Theory says lognormal has a heavier tail than gamma; diagnostics are
  consistent but the difference is small in this dataset.
\item
  Both models exhibit very similar tail behaviour on residuals and
  nearidentical predictive accuracy.
\item
  the gamma model is a reasonable, slightly betterscoring choice.
\end{itemize}

\section{Investigation of claim
outcome}\label{investigation-of-claim-outcome}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{claimoutcome\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_data\_imputed }\SpecialCharTok{\%\textgreater{}\%}\FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{CLAIMS)}
\FunctionTok{mean}\NormalTok{(claimoutcome\_df}\SpecialCharTok{$}\NormalTok{OUTCOME)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.31675
\end{verbatim}

\subsection{logistic regression}\label{logistic-regression}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# full basic model without interaction terms}
\NormalTok{outcome.}\FloatTok{0.}\NormalTok{logistic }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(OUTCOME }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                              \AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"logit"}\NormalTok{),}
                              \AttributeTok{data =}\NormalTok{ claimoutcome\_df)}

\CommentTok{\# full model with interaction terms}
\NormalTok{outcome.}\FloatTok{1.}\NormalTok{logistic }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(OUTCOME }\SpecialCharTok{\textasciitilde{}}\NormalTok{(AGE }\SpecialCharTok{+}\NormalTok{ GENDER }\SpecialCharTok{+}\NormalTok{ DRIVING\_EXPERIENCE }\SpecialCharTok{+}\NormalTok{ EDUCATION }\SpecialCharTok{+}
\NormalTok{                             CREDIT\_SCORE }\SpecialCharTok{+}\NormalTok{ VEHICLE\_OWNERSHIP }\SpecialCharTok{+}\NormalTok{ VEHICLE\_YEAR }\SpecialCharTok{+}
\NormalTok{                             MARRIED }\SpecialCharTok{+}\NormalTok{ CHILDREN }\SpecialCharTok{+}\NormalTok{ ANNUAL\_MILEAGE }\SpecialCharTok{+}
\NormalTok{                             VEHICLE\_TYPE }\SpecialCharTok{+}\NormalTok{ SPEEDING\_VIOLATIONS }\SpecialCharTok{+}\NormalTok{ PAST\_ACCIDENTS)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
                          \AttributeTok{family=} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"logit"}\NormalTok{),}
                          \AttributeTok{data =}\NormalTok{ claimoutcome\_df)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Variable selection}\label{variable-selection-2}

Stepwise selection based on AIC

\begin{verbatim}
## 
## Call:
## glm(formula = OUTCOME ~ DRIVING_EXPERIENCE + VEHICLE_OWNERSHIP + 
##     VEHICLE_YEAR + GENDER + MARRIED + PAST_ACCIDENTS + ANNUAL_MILEAGE + 
##     SPEEDING_VIOLATIONS + DRIVING_EXPERIENCE:VEHICLE_YEAR + VEHICLE_OWNERSHIP:SPEEDING_VIOLATIONS + 
##     GENDER:MARRIED, family = binomial(link = "logit"), data = claimoutcome_df)
## 
## Coefficients:
##                                                    Estimate Std. Error z value
## (Intercept)                                      -8.220e-01  2.229e-01  -3.687
## DRIVING_EXPERIENCE10-19y                         -1.533e+00  1.808e-01  -8.477
## DRIVING_EXPERIENCE20-29y                         -2.237e+00  2.768e-01  -8.082
## DRIVING_EXPERIENCE30y+                           -2.634e+00  4.387e-01  -6.004
## VEHICLE_OWNERSHIP                                -1.897e+00  8.301e-02 -22.847
## VEHICLE_YEARbefore 2015                           2.093e+00  1.152e-01  18.169
## GENDERmale                                        8.538e-01  8.904e-02   9.588
## MARRIED                                          -6.910e-01  1.087e-01  -6.355
## PAST_ACCIDENTS                                   -2.149e-01  3.877e-02  -5.542
## ANNUAL_MILEAGE                                    6.917e-05  1.440e-05   4.803
## SPEEDING_VIOLATIONS                               4.719e-03  3.758e-02   0.126
## DRIVING_EXPERIENCE10-19y:VEHICLE_YEARbefore 2015 -4.730e-01  1.903e-01  -2.486
## DRIVING_EXPERIENCE20-29y:VEHICLE_YEARbefore 2015 -1.423e+00  2.936e-01  -4.847
## DRIVING_EXPERIENCE30y+:VEHICLE_YEARbefore 2015   -2.037e+00  5.280e-01  -3.859
## VEHICLE_OWNERSHIP:SPEEDING_VIOLATIONS             1.282e-01  3.976e-02   3.224
## GENDERmale:MARRIED                                4.189e-01  1.381e-01   3.032
##                                                  Pr(>|z|)    
## (Intercept)                                      0.000227 ***
## DRIVING_EXPERIENCE10-19y                          < 2e-16 ***
## DRIVING_EXPERIENCE20-29y                         6.35e-16 ***
## DRIVING_EXPERIENCE30y+                           1.92e-09 ***
## VEHICLE_OWNERSHIP                                 < 2e-16 ***
## VEHICLE_YEARbefore 2015                           < 2e-16 ***
## GENDERmale                                        < 2e-16 ***
## MARRIED                                          2.08e-10 ***
## PAST_ACCIDENTS                                   2.98e-08 ***
## ANNUAL_MILEAGE                                   1.56e-06 ***
## SPEEDING_VIOLATIONS                              0.900080    
## DRIVING_EXPERIENCE10-19y:VEHICLE_YEARbefore 2015 0.012923 *  
## DRIVING_EXPERIENCE20-29y:VEHICLE_YEARbefore 2015 1.25e-06 ***
## DRIVING_EXPERIENCE30y+:VEHICLE_YEARbefore 2015   0.000114 ***
## VEHICLE_OWNERSHIP:SPEEDING_VIOLATIONS            0.001263 ** 
## GENDERmale:MARRIED                               0.002426 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 9990.3  on 7999  degrees of freedom
## Residual deviance: 5717.5  on 7984  degrees of freedom
## AIC: 5749.5
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\subsubsection{hypothesis tests}\label{hypothesis-tests}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Align both models to the exact same rows used in the full model}
\NormalTok{mf }\OtherTok{\textless{}{-}} \FunctionTok{model.frame}\NormalTok{(outcome.}\FloatTok{1.}\NormalTok{logistic)}
\NormalTok{reduced }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{logistic, }\AttributeTok{data =}\NormalTok{ mf)}

\CommentTok{\# Likelihood{-}ratio test (valid when reduced is nested in full)}
\FunctionTok{anova}\NormalTok{(reduced, outcome.}\FloatTok{1.}\NormalTok{logistic, }\AttributeTok{test =} \StringTok{"Chisq"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: OUTCOME ~ DRIVING_EXPERIENCE + VEHICLE_OWNERSHIP + VEHICLE_YEAR + 
##     GENDER + MARRIED + PAST_ACCIDENTS + ANNUAL_MILEAGE + SPEEDING_VIOLATIONS + 
##     DRIVING_EXPERIENCE:VEHICLE_YEAR + VEHICLE_OWNERSHIP:SPEEDING_VIOLATIONS + 
##     GENDER:MARRIED
## Model 2: OUTCOME ~ (AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION + CREDIT_SCORE + 
##     VEHICLE_OWNERSHIP + VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + 
##     VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2
##   Resid. Df Resid. Dev  Df Deviance Pr(>Chi)  
## 1      7984     5717.5                        
## 2      7845     5542.3 139   175.15   0.0205 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# AIC and BIC (smaller is better)}
\FunctionTok{AIC}\NormalTok{(reduced, outcome.}\FloatTok{1.}\NormalTok{logistic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     df      AIC
## reduced             16 5749.453
## outcome.1.logistic 155 5852.303
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nobs}\NormalTok{(outcome.}\FloatTok{1.}\NormalTok{logistic)}
\FunctionTok{AIC}\NormalTok{(reduced, outcome.}\FloatTok{1.}\NormalTok{logistic, }\AttributeTok{k =} \FunctionTok{log}\NormalTok{(n))  }\CommentTok{\# BIC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     df      AIC
## reduced             16 5861.248
## outcome.1.logistic 155 6935.318
\end{verbatim}

\begin{itemize}
\tightlist
\item
  The LR test suggests some in-sample gain from the full model, but
  parsimony (AIC/BIC) and predictive validation likely favor the reduced
  model unless you see a clear lift on a hold-out set.
\end{itemize}

\subsubsection{Residual analysis and finding influential
points}\label{residual-analysis-and-finding-influential-points}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{logistic, }\AttributeTok{type =} \StringTok{"deviance"}\NormalTok{), }\AttributeTok{main =} \StringTok{"Histogram of Deviance Residuals"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Deviance Residuals"}\NormalTok{, }\AttributeTok{breaks =} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-46-1.pdf}}
- we see a non normal shape as the response variable is discrete and has
a high number of 0's - look at randomised quantile residuals instead

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qres }\OtherTok{\textless{}{-}} \FunctionTok{qresiduals}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{logistic)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)) }\CommentTok{\# Set up a 1x2 plotting area}
\FunctionTok{hist}\NormalTok{(qres, }\AttributeTok{main =} \StringTok{"Histogram of Quantile Residuals"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Quantile Residuals"}\NormalTok{)}
\FunctionTok{qqnorm}\NormalTok{(qres, }\AttributeTok{main =} \StringTok{"Normal Q{-}Q Plot"}\NormalTok{)}
\FunctionTok{qqline}\NormalTok{(qres, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-47-1.pdf}}
- We see that the quantile residuals are normally distributed, and the
qq plot shows a very close fit to the normal distribution, suggesting
that our logistic regression model is appropriate for the data.

\subsection{Probit regression}\label{probit-regression}

\begin{itemize}
\tightlist
\item
  using binomial with probit link
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# full basic model without interaction terms}
\NormalTok{outcome.}\FloatTok{0.}\NormalTok{probit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(OUTCOME }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}
                        \AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"probit"}\NormalTok{),}
                        \AttributeTok{data =}\NormalTok{ claimoutcome\_df)}

\CommentTok{\# full model with interaction terms}
\NormalTok{outcome.}\FloatTok{1.}\NormalTok{probit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(OUTCOME }\SpecialCharTok{\textasciitilde{}}\NormalTok{(AGE }\SpecialCharTok{+}\NormalTok{ GENDER }\SpecialCharTok{+}\NormalTok{ DRIVING\_EXPERIENCE }\SpecialCharTok{+}\NormalTok{ EDUCATION }\SpecialCharTok{+}
\NormalTok{                                  CREDIT\_SCORE }\SpecialCharTok{+}\NormalTok{ VEHICLE\_OWNERSHIP }\SpecialCharTok{+}\NormalTok{ VEHICLE\_YEAR }\SpecialCharTok{+}
\NormalTok{                                  MARRIED }\SpecialCharTok{+}\NormalTok{ CHILDREN }\SpecialCharTok{+}\NormalTok{ ANNUAL\_MILEAGE }\SpecialCharTok{+}
\NormalTok{                                  VEHICLE\_TYPE }\SpecialCharTok{+}\NormalTok{ SPEEDING\_VIOLATIONS }\SpecialCharTok{+}\NormalTok{ PAST\_ACCIDENTS)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
                        \AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"probit"}\NormalTok{),}
                        \AttributeTok{data =}\NormalTok{ claimoutcome\_df)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Variable selection}\label{variable-selection-3}

\begin{verbatim}
## 
## Call:
## glm(formula = OUTCOME ~ DRIVING_EXPERIENCE + VEHICLE_OWNERSHIP + 
##     VEHICLE_YEAR + GENDER + MARRIED + PAST_ACCIDENTS + ANNUAL_MILEAGE + 
##     SPEEDING_VIOLATIONS + DRIVING_EXPERIENCE:VEHICLE_YEAR + DRIVING_EXPERIENCE:VEHICLE_OWNERSHIP + 
##     VEHICLE_OWNERSHIP:PAST_ACCIDENTS, family = binomial(link = "probit"), 
##     data = claimoutcome_df)
## 
## Coefficients:
##                                                    Estimate Std. Error z value
## (Intercept)                                      -5.178e-01  1.279e-01  -4.048
## DRIVING_EXPERIENCE10-19y                         -9.270e-01  1.131e-01  -8.197
## DRIVING_EXPERIENCE20-29y                         -1.676e+00  1.702e-01  -9.850
## DRIVING_EXPERIENCE30y+                           -2.302e+00  3.638e-01  -6.329
## VEHICLE_OWNERSHIP                                -1.105e+00  6.052e-02 -18.265
## VEHICLE_YEARbefore 2015                           1.234e+00  6.595e-02  18.708
## GENDERmale                                        5.655e-01  4.024e-02  14.051
## MARRIED                                          -2.609e-01  4.308e-02  -6.056
## PAST_ACCIDENTS                                   -4.949e-02  3.117e-02  -1.588
## ANNUAL_MILEAGE                                    3.933e-05  8.090e-06   4.861
## SPEEDING_VIOLATIONS                               4.211e-02  1.370e-02   3.073
## DRIVING_EXPERIENCE10-19y:VEHICLE_YEARbefore 2015 -3.399e-01  1.043e-01  -3.258
## DRIVING_EXPERIENCE20-29y:VEHICLE_YEARbefore 2015 -8.933e-01  1.392e-01  -6.417
## DRIVING_EXPERIENCE30y+:VEHICLE_YEARbefore 2015   -1.128e+00  2.288e-01  -4.931
## DRIVING_EXPERIENCE10-19y:VEHICLE_OWNERSHIP        1.597e-01  9.360e-02   1.707
## DRIVING_EXPERIENCE20-29y:VEHICLE_OWNERSHIP        8.736e-01  1.504e-01   5.809
## DRIVING_EXPERIENCE30y+:VEHICLE_OWNERSHIP          1.456e+00  3.472e-01   4.193
## VEHICLE_OWNERSHIP:PAST_ACCIDENTS                 -1.342e-01  4.131e-02  -3.248
##                                                  Pr(>|z|)    
## (Intercept)                                      5.16e-05 ***
## DRIVING_EXPERIENCE10-19y                         2.46e-16 ***
## DRIVING_EXPERIENCE20-29y                          < 2e-16 ***
## DRIVING_EXPERIENCE30y+                           2.47e-10 ***
## VEHICLE_OWNERSHIP                                 < 2e-16 ***
## VEHICLE_YEARbefore 2015                           < 2e-16 ***
## GENDERmale                                        < 2e-16 ***
## MARRIED                                          1.39e-09 ***
## PAST_ACCIDENTS                                    0.11230    
## ANNUAL_MILEAGE                                   1.17e-06 ***
## SPEEDING_VIOLATIONS                               0.00212 ** 
## DRIVING_EXPERIENCE10-19y:VEHICLE_YEARbefore 2015  0.00112 ** 
## DRIVING_EXPERIENCE20-29y:VEHICLE_YEARbefore 2015 1.39e-10 ***
## DRIVING_EXPERIENCE30y+:VEHICLE_YEARbefore 2015   8.20e-07 ***
## DRIVING_EXPERIENCE10-19y:VEHICLE_OWNERSHIP        0.08791 .  
## DRIVING_EXPERIENCE20-29y:VEHICLE_OWNERSHIP       6.29e-09 ***
## DRIVING_EXPERIENCE30y+:VEHICLE_OWNERSHIP         2.76e-05 ***
## VEHICLE_OWNERSHIP:PAST_ACCIDENTS                  0.00116 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 9990.3  on 7999  degrees of freedom
## Residual deviance: 5711.9  on 7982  degrees of freedom
## AIC: 5747.9
## 
## Number of Fisher Scoring iterations: 7
\end{verbatim}

\subsubsection{hypothesis tests}\label{hypothesis-tests-1}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ensure both models use identical rows}
\NormalTok{mf }\OtherTok{\textless{}{-}} \FunctionTok{model.frame}\NormalTok{(outcome.}\FloatTok{1.}\NormalTok{probit)}
\NormalTok{reduced }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{probit, }\AttributeTok{data =}\NormalTok{ mf)}

\CommentTok{\# Likelihood{-}ratio test (Model 1 = reduced, Model 2 = full)}
\FunctionTok{anova}\NormalTok{(reduced, outcome.}\FloatTok{1.}\NormalTok{probit, }\AttributeTok{test =} \StringTok{"Chisq"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Deviance Table
## 
## Model 1: OUTCOME ~ DRIVING_EXPERIENCE + VEHICLE_OWNERSHIP + VEHICLE_YEAR + 
##     GENDER + MARRIED + PAST_ACCIDENTS + ANNUAL_MILEAGE + SPEEDING_VIOLATIONS + 
##     DRIVING_EXPERIENCE:VEHICLE_YEAR + DRIVING_EXPERIENCE:VEHICLE_OWNERSHIP + 
##     VEHICLE_OWNERSHIP:PAST_ACCIDENTS
## Model 2: OUTCOME ~ (AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION + CREDIT_SCORE + 
##     VEHICLE_OWNERSHIP + VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + 
##     VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2
##   Resid. Df Resid. Dev  Df Deviance Pr(>Chi)  
## 1      7982     5711.9                        
## 2      7845     5544.3 137   167.56  0.03888 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# AIC and BIC comparison (smaller is better)}
\FunctionTok{AIC}\NormalTok{(reduced, outcome.}\FloatTok{1.}\NormalTok{probit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                   df      AIC
## reduced           18 5747.855
## outcome.1.probit 155 5854.298
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nobs}\NormalTok{(outcome.}\FloatTok{1.}\NormalTok{probit)}
\FunctionTok{AIC}\NormalTok{(reduced, outcome.}\FloatTok{1.}\NormalTok{probit, }\AttributeTok{k =} \FunctionTok{log}\NormalTok{(n))  }\CommentTok{\# BIC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                   df      AIC
## reduced           18 5873.625
## outcome.1.probit 155 6937.313
\end{verbatim}

\subsection{Comparison between logit and probit link
functions}\label{comparison-between-logit-and-probit-link-functions}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Helpers}
\NormalTok{prep\_newdata\_for }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(newdata, fit) \{}
\NormalTok{  nd }\OtherTok{\textless{}{-}}\NormalTok{ newdata}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{xlevels)) \{}
    \ControlFlowTok{for}\NormalTok{ (nm }\ControlFlowTok{in} \FunctionTok{names}\NormalTok{(fit}\SpecialCharTok{$}\NormalTok{xlevels)) }\ControlFlowTok{if}\NormalTok{ (nm }\SpecialCharTok{\%in\%} \FunctionTok{names}\NormalTok{(nd)) \{}
\NormalTok{      nd[[nm]] }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(nd[[nm]], }\AttributeTok{levels =}\NormalTok{ fit}\SpecialCharTok{$}\NormalTok{xlevels[[nm]])}
\NormalTok{    \}}
\NormalTok{  \}}
  \FunctionTok{droplevels}\NormalTok{(nd)}
\NormalTok{\}}
\NormalTok{log\_loss }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y, p, }\AttributeTok{eps =} \FloatTok{1e{-}15}\NormalTok{) \{}
\NormalTok{  p }\OtherTok{\textless{}{-}} \FunctionTok{pmin}\NormalTok{(}\FunctionTok{pmax}\NormalTok{(p, eps), }\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ eps)}
  \SpecialCharTok{{-}}\FunctionTok{mean}\NormalTok{(y }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ y) }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{\}}
\NormalTok{brier }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y, p) }\FunctionTok{mean}\NormalTok{((p }\SpecialCharTok{{-}}\NormalTok{ y)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{calibration\_df }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y, p, }\AttributeTok{bins =} \DecValTok{10}\NormalTok{, }\AttributeTok{label =} \StringTok{"model"}\NormalTok{) \{}
\NormalTok{  brks }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(p, }\AttributeTok{probs =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ bins }\SpecialCharTok{+} \DecValTok{1}\NormalTok{), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  g }\OtherTok{\textless{}{-}} \FunctionTok{cut}\NormalTok{(p, }\AttributeTok{breaks =} \FunctionTok{unique}\NormalTok{(brks), }\AttributeTok{include.lowest =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{summarise}\NormalTok{(dplyr}\SpecialCharTok{::}\FunctionTok{group\_by}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(y, p, g), g),}
                   \AttributeTok{mean\_p =} \FunctionTok{mean}\NormalTok{(p, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
                   \AttributeTok{obs   =} \FunctionTok{mean}\NormalTok{(y, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
                   \AttributeTok{n     =}\NormalTok{ dplyr}\SpecialCharTok{::}\FunctionTok{n}\NormalTok{()) }\SpecialCharTok{|\textgreater{}}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{model =}\NormalTok{ label)}
\NormalTok{\}}

\CommentTok{\# Prepare test data for each model (handles factors/levels)}
\NormalTok{test\_logit  }\OtherTok{\textless{}{-}} \FunctionTok{prep\_newdata\_for}\NormalTok{(test\_data\_imputed, outcome.}\FloatTok{2.}\NormalTok{logistic)}
\NormalTok{test\_probit }\OtherTok{\textless{}{-}} \FunctionTok{prep\_newdata\_for}\NormalTok{(test\_data\_imputed, outcome.}\FloatTok{2.}\NormalTok{probit)}

\CommentTok{\# Predictions}
\NormalTok{y  }\OtherTok{\textless{}{-}}\NormalTok{ test\_logit}\SpecialCharTok{$}\NormalTok{OUTCOME}
\NormalTok{p\_logit  }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{logistic, }\AttributeTok{newdata =}\NormalTok{ test\_logit,  }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{p\_probit }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{probit,   }\AttributeTok{newdata =}\NormalTok{ test\_probit, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\CommentTok{\# Keep rows where both models produce probabilities}
\NormalTok{keep }\OtherTok{\textless{}{-}} \FunctionTok{is.finite}\NormalTok{(p\_logit) }\SpecialCharTok{\&} \FunctionTok{is.finite}\NormalTok{(p\_probit) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(y)}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ y[keep]; p\_logit }\OtherTok{\textless{}{-}}\NormalTok{ p\_logit[keep]; p\_probit }\OtherTok{\textless{}{-}}\NormalTok{ p\_probit[keep]}

\CommentTok{\# Build ROC objects with pROC}
\NormalTok{roc\_logit  }\OtherTok{\textless{}{-}}\NormalTok{ pROC}\SpecialCharTok{::}\FunctionTok{roc}\NormalTok{(y, p\_logit,  }\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{roc\_probit }\OtherTok{\textless{}{-}}\NormalTok{ pROC}\SpecialCharTok{::}\FunctionTok{roc}\NormalTok{(y, p\_probit, }\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# Get numeric AUCs (either of these styles works)}
\NormalTok{auc\_logit  }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(pROC}\SpecialCharTok{::}\FunctionTok{auc}\NormalTok{(roc\_logit))}
\NormalTok{auc\_probit }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(pROC}\SpecialCharTok{::}\FunctionTok{auc}\NormalTok{(roc\_probit))}
\CommentTok{\# or:}
\CommentTok{\# auc\_logit  \textless{}{-} as.numeric(roc\_logit$auc)}
\CommentTok{\# auc\_probit \textless{}{-} as.numeric(roc\_probit$auc)}

\NormalTok{metrics }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Model   =} \FunctionTok{c}\NormalTok{(}\StringTok{"Logit"}\NormalTok{, }\StringTok{"Probit"}\NormalTok{),}
  \AttributeTok{AUC     =} \FunctionTok{c}\NormalTok{(auc\_logit, auc\_probit),}
  \AttributeTok{LogLoss =} \FunctionTok{c}\NormalTok{(}\FunctionTok{log\_loss}\NormalTok{(y, p\_logit),  }\FunctionTok{log\_loss}\NormalTok{(y, p\_probit)),}
  \AttributeTok{Brier   =} \FunctionTok{c}\NormalTok{(}\FunctionTok{brier}\NormalTok{(y, p\_logit),     }\FunctionTok{brier}\NormalTok{(y, p\_probit))}
\NormalTok{)}
\FunctionTok{print}\NormalTok{(metrics, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Model       AUC   LogLoss     Brier
##   Logit 0.8811706 0.3921841 0.1246430
##  Probit 0.8817748 0.3903196 0.1242813
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# AUC difference test}
\NormalTok{auc\_test }\OtherTok{\textless{}{-}}\NormalTok{ pROC}\SpecialCharTok{::}\FunctionTok{roc.test}\NormalTok{(roc\_logit, roc\_probit, }\AttributeTok{method =} \StringTok{"delong"}\NormalTok{)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{DeLong test for AUC difference: z = \%.3f, p = \%.4f}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{,}
\NormalTok{            auc\_test}\SpecialCharTok{$}\NormalTok{statistic, auc\_test}\SpecialCharTok{$}\NormalTok{p.value))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## DeLong test for AUC difference: z = -0.580, p = 0.5618
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ROC curves (overlaid)}
\NormalTok{df\_roc\_logit }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{fpr =} \FunctionTok{rev}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ roc\_logit}\SpecialCharTok{$}\NormalTok{specificities),}
  \AttributeTok{tpr =} \FunctionTok{rev}\NormalTok{(roc\_logit}\SpecialCharTok{$}\NormalTok{sensitivities),}
  \AttributeTok{model =} \StringTok{"Logit"}
\NormalTok{)}
\NormalTok{df\_roc\_probit }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{fpr =} \FunctionTok{rev}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ roc\_probit}\SpecialCharTok{$}\NormalTok{specificities),}
  \AttributeTok{tpr =} \FunctionTok{rev}\NormalTok{(roc\_probit}\SpecialCharTok{$}\NormalTok{sensitivities),}
  \AttributeTok{model =} \StringTok{"Probit"}
\NormalTok{)}
\NormalTok{df\_roc }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(df\_roc\_logit, df\_roc\_probit)}

\NormalTok{p\_roc }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(df\_roc, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ fpr, }\AttributeTok{y =}\NormalTok{ tpr, }\AttributeTok{color =}\NormalTok{ model)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{slope =} \DecValTok{1}\NormalTok{, }\AttributeTok{intercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{, }\AttributeTok{color =} \StringTok{"gray50"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \FunctionTok{sprintf}\NormalTok{(}\StringTok{"ROC on test (AUC: logit=\%.3f, probit=\%.3f)"}\NormalTok{,}
\NormalTok{                       metrics}\SpecialCharTok{$}\NormalTok{AUC[metrics}\SpecialCharTok{$}\NormalTok{Model}\SpecialCharTok{==}\StringTok{"Logit"}\NormalTok{],}
\NormalTok{                       metrics}\SpecialCharTok{$}\NormalTok{AUC[metrics}\SpecialCharTok{$}\NormalTok{Model}\SpecialCharTok{==}\StringTok{"Probit"}\NormalTok{]),}
       \AttributeTok{x =} \StringTok{"False Positive Rate"}\NormalTok{, }\AttributeTok{y =} \StringTok{"True Positive Rate"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+} \FunctionTok{coord\_equal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## i Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(p\_roc)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-51-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calibration (reliability) plot}
\NormalTok{cal\_logit  }\OtherTok{\textless{}{-}} \FunctionTok{calibration\_df}\NormalTok{(y, p\_logit,  }\AttributeTok{bins =} \DecValTok{10}\NormalTok{, }\AttributeTok{label =} \StringTok{"Logit"}\NormalTok{)}
\NormalTok{cal\_probit }\OtherTok{\textless{}{-}} \FunctionTok{calibration\_df}\NormalTok{(y, p\_probit, }\AttributeTok{bins =} \DecValTok{10}\NormalTok{, }\AttributeTok{label =} \StringTok{"Probit"}\NormalTok{)}
\NormalTok{cal }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(cal\_logit, cal\_probit)}

\NormalTok{p\_cal }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(cal, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mean\_p, }\AttributeTok{y =}\NormalTok{ obs, }\AttributeTok{color =}\NormalTok{ model, }\AttributeTok{size =}\NormalTok{ n)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{slope =} \DecValTok{1}\NormalTok{, }\AttributeTok{intercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{, }\AttributeTok{color =} \StringTok{"gray50"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_size\_continuous}\NormalTok{(}\AttributeTok{name =} \StringTok{"Bin N"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Calibration on test (10 quantile bins)"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Mean predicted probability"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Observed frequency"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\FunctionTok{print}\NormalTok{(p\_cal)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-51-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Optional: density of predicted probabilities by class (separation plot)}
\NormalTok{df\_prob }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{y =} \FunctionTok{factor}\NormalTok{(y, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)),}
                      \AttributeTok{logit =}\NormalTok{ p\_logit, }\AttributeTok{probit =}\NormalTok{ p\_probit) }\SpecialCharTok{|\textgreater{}}
\NormalTok{  tidyr}\SpecialCharTok{::}\FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{c}\NormalTok{(logit, probit), }\AttributeTok{names\_to =} \StringTok{"model"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"p"}\NormalTok{)}
\NormalTok{p\_den }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(df\_prob, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p, }\AttributeTok{fill =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.35}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ model, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"Predicted probability densities by outcome (test)"}\NormalTok{,}
       \AttributeTok{x =} \StringTok{"Predicted probability"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Density"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Outcome"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\FunctionTok{print}\NormalTok{(p\_den)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{assignment_files/figure-latex/unnamed-chunk-51-3.pdf}}

\begin{itemize}
\item
  Predictedprobability densities by outcome Clear separation: class 0
  probabilities are heavily concentrated near 0; class 1 probabilities
  are mostly 0.5--1.0 with a peak near 0.8--0.95. Overlap is mainly in
  0.1--0.3, which is where most errors will occur. Logit vs probit look
  almost identical; probit shows a hair more mass near very high
  probabilities, but the difference is tiny.
\item
  Calibration (10 quantile bins) Points lie very close to the 45 line
  for both models across the range  wellcalibrated probabilities.
  Minor, likely noiselevel deviations: around 0.7--0.8 the probit is
  slightly underconfident (observed \textgreater{} predicted), around
  \textasciitilde0.55 the logit is slightly overconfident. Bin sizes are
  \textasciitilde200, so sampling variation can explain this.
\item
  ROC and AUC Curves overlap almost perfectly; test AUCs are 0.881
  (logit) vs 0.882 (probit). The 0.001 gap is negligible and would not
  be statistically or practically significant (DeLong test would almost
  surely be nonsignificant). Bottom line
\item
  On the test set, logit and probit are essentially indistinguishable
\item
  Choose Logit due to its superior explanatory power
\end{itemize}

\section{Final model}\label{final-model}

\begin{itemize}
\tightlist
\item
  Binomial with logit link for claim occurrence
\item
  Gamma GLM with log link for claim severity
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# kNN{-}impute numeric predictors and refit models on data\_imputed}

\CommentTok{\# Predictors used by either model (exclude responses)}
\NormalTok{pred\_vars }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}
  \FunctionTok{unique}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FunctionTok{all.vars}\NormalTok{(}\FunctionTok{formula}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{logistic))[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{],}
           \FunctionTok{all.vars}\NormalTok{(}\FunctionTok{formula}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma))[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])),}
  \FunctionTok{c}\NormalTok{(}\StringTok{"OUTCOME"}\NormalTok{, }\StringTok{"CLAIMS"}\NormalTok{)}
\NormalTok{)}

\CommentTok{\# Numeric predictors to impute}
\NormalTok{num\_vars }\OtherTok{\textless{}{-}} \FunctionTok{intersect}\NormalTok{(pred\_vars, }\FunctionTok{names}\NormalTok{(}\FunctionTok{Filter}\NormalTok{(is.numeric, data)))}

\CommentTok{\# Train kNN imputer (k = 5) on training numerics and impute}
\NormalTok{rec }\OtherTok{\textless{}{-}} \FunctionTok{recipe}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ data[, num\_vars, }\AttributeTok{drop =} \ConstantTok{FALSE}\NormalTok{]) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{step\_impute\_knn}\NormalTok{(}\FunctionTok{all\_predictors}\NormalTok{(), }\AttributeTok{neighbors =} \DecValTok{5}\NormalTok{)}
\NormalTok{imp }\OtherTok{\textless{}{-}} \FunctionTok{prep}\NormalTok{(rec, }\AttributeTok{training =}\NormalTok{ data[, num\_vars, }\AttributeTok{drop =} \ConstantTok{FALSE}\NormalTok{], }\AttributeTok{retain =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{data\_imputed }\OtherTok{\textless{}{-}}\NormalTok{ data}
\NormalTok{data\_imputed[, num\_vars] }\OtherTok{\textless{}{-}} \FunctionTok{bake}\NormalTok{(imp, }\AttributeTok{new\_data =}\NormalTok{ data[, num\_vars, }\AttributeTok{drop =} \ConstantTok{FALSE}\NormalTok{])}


\CommentTok{\# Refit models with identical specs on imputed data}
\NormalTok{claimsize.}\FloatTok{3.}\NormalTok{gamma  }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(claimsize.}\FloatTok{2.}\NormalTok{gamma,  }\AttributeTok{data =}\NormalTok{ data\_imputed[data\_imputed}\SpecialCharTok{$}\NormalTok{CLAIMS }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{, ])}
\NormalTok{outcome.}\FloatTok{3.}\NormalTok{logistic }\OtherTok{\textless{}{-}} \FunctionTok{update}\NormalTok{(outcome.}\FloatTok{2.}\NormalTok{logistic, }\AttributeTok{data =}\NormalTok{ data\_imputed)}
\end{Highlighting}
\end{Shaded}

\subsection{summaries of final models}\label{summaries-of-final-models}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(claimsize.}\FloatTok{3.}\NormalTok{gamma)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = CLAIMS ~ GENDER + DRIVING_EXPERIENCE + CREDIT_SCORE + 
##     VEHICLE_YEAR + MARRIED + CHILDREN + ANNUAL_MILEAGE + VEHICLE_TYPE + 
##     SPEEDING_VIOLATIONS + PAST_ACCIDENTS + GENDER:CHILDREN + 
##     CHILDREN:ANNUAL_MILEAGE + CREDIT_SCORE:PAST_ACCIDENTS + VEHICLE_YEAR:MARRIED + 
##     GENDER:SPEEDING_VIOLATIONS + CREDIT_SCORE:VEHICLE_TYPE, family = Gamma(link = "log"), 
##     data = data_imputed[data_imputed$CLAIMS > 0, ], control = glm.control(maxit = 100))
## 
## Coefficients:
##                                       Estimate Std. Error t value Pr(>|t|)    
## (Intercept)                          8.670e+00  2.119e-01  40.917  < 2e-16 ***
## GENDERmale                           2.873e-01  5.923e-02   4.851 1.29e-06 ***
## DRIVING_EXPERIENCE10-19y            -6.185e-01  6.432e-02  -9.616  < 2e-16 ***
## DRIVING_EXPERIENCE20-29y            -6.235e-01  1.387e-01  -4.494 7.23e-06 ***
## DRIVING_EXPERIENCE30y+              -2.508e-01  2.765e-01  -0.907  0.36448    
## CREDIT_SCORE                         4.180e-01  1.755e-01   2.382  0.01728 *  
## VEHICLE_YEARbefore 2015              1.805e-01  8.512e-02   2.120  0.03409 *  
## MARRIED                              1.746e-01  1.275e-01   1.369  0.17098    
## CHILDREN                            -6.274e-01  2.178e-01  -2.881  0.00399 ** 
## ANNUAL_MILEAGE                      -9.846e-06  1.211e-05  -0.813  0.41620    
## VEHICLE_TYPEsports car               5.836e-01  3.300e-01   1.768  0.07709 .  
## SPEEDING_VIOLATIONS                 -3.992e-02  4.470e-02  -0.893  0.37195    
## PAST_ACCIDENTS                       2.318e-01  1.006e-01   2.304  0.02127 *  
## GENDERmale:CHILDREN                  2.179e-01  8.137e-02   2.677  0.00746 ** 
## CHILDREN:ANNUAL_MILEAGE              3.811e-05  1.619e-05   2.354  0.01862 *  
## CREDIT_SCORE:PAST_ACCIDENTS         -4.728e-01  2.033e-01  -2.325  0.02013 *  
## VEHICLE_YEARbefore 2015:MARRIED     -2.353e-01  1.335e-01  -1.762  0.07817 .  
## GENDERmale:SPEEDING_VIOLATIONS       8.007e-02  4.358e-02   1.837  0.06629 .  
## CREDIT_SCORE:VEHICLE_TYPEsports car -8.767e-01  6.876e-01  -1.275  0.20239    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for Gamma family taken to be 1.223407)
## 
##     Null deviance: 3675.6  on 3132  degrees of freedom
## Residual deviance: 3338.0  on 3114  degrees of freedom
## AIC: 61846
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(outcome.}\FloatTok{3.}\NormalTok{logistic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = OUTCOME ~ DRIVING_EXPERIENCE + VEHICLE_OWNERSHIP + 
##     VEHICLE_YEAR + GENDER + MARRIED + PAST_ACCIDENTS + ANNUAL_MILEAGE + 
##     SPEEDING_VIOLATIONS + DRIVING_EXPERIENCE:VEHICLE_YEAR + VEHICLE_OWNERSHIP:SPEEDING_VIOLATIONS + 
##     GENDER:MARRIED, family = binomial(link = "logit"), data = data_imputed)
## 
## Coefficients:
##                                                    Estimate Std. Error z value
## (Intercept)                                      -6.576e-01  1.958e-01  -3.359
## DRIVING_EXPERIENCE10-19y                         -1.518e+00  1.611e-01  -9.421
## DRIVING_EXPERIENCE20-29y                         -2.201e+00  2.427e-01  -9.069
## DRIVING_EXPERIENCE30y+                           -2.693e+00  4.046e-01  -6.657
## VEHICLE_OWNERSHIP                                -1.821e+00  7.295e-02 -24.961
## VEHICLE_YEARbefore 2015                           1.990e+00  1.011e-01  19.679
## GENDERmale                                        8.221e-01  7.876e-02  10.437
## MARRIED                                          -6.517e-01  9.515e-02  -6.849
## PAST_ACCIDENTS                                   -2.217e-01  3.470e-02  -6.388
## ANNUAL_MILEAGE                                    5.524e-05  1.253e-05   4.408
## SPEEDING_VIOLATIONS                               1.956e-03  3.370e-02   0.058
## DRIVING_EXPERIENCE10-19y:VEHICLE_YEARbefore 2015 -3.851e-01  1.692e-01  -2.276
## DRIVING_EXPERIENCE20-29y:VEHICLE_YEARbefore 2015 -1.396e+00  2.583e-01  -5.405
## DRIVING_EXPERIENCE30y+:VEHICLE_YEARbefore 2015   -1.832e+00  4.769e-01  -3.841
## VEHICLE_OWNERSHIP:SPEEDING_VIOLATIONS             1.265e-01  3.564e-02   3.550
## GENDERmale:MARRIED                                3.524e-01  1.217e-01   2.896
##                                                  Pr(>|z|)    
## (Intercept)                                      0.000781 ***
## DRIVING_EXPERIENCE10-19y                          < 2e-16 ***
## DRIVING_EXPERIENCE20-29y                          < 2e-16 ***
## DRIVING_EXPERIENCE30y+                           2.79e-11 ***
## VEHICLE_OWNERSHIP                                 < 2e-16 ***
## VEHICLE_YEARbefore 2015                           < 2e-16 ***
## GENDERmale                                        < 2e-16 ***
## MARRIED                                          7.42e-12 ***
## PAST_ACCIDENTS                                   1.68e-10 ***
## ANNUAL_MILEAGE                                   1.04e-05 ***
## SPEEDING_VIOLATIONS                              0.953723    
## DRIVING_EXPERIENCE10-19y:VEHICLE_YEARbefore 2015 0.022842 *  
## DRIVING_EXPERIENCE20-29y:VEHICLE_YEARbefore 2015 6.48e-08 ***
## DRIVING_EXPERIENCE30y+:VEHICLE_YEARbefore 2015   0.000122 ***
## VEHICLE_OWNERSHIP:SPEEDING_VIOLATIONS            0.000385 ***
## GENDERmale:MARRIED                               0.003785 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 12434.3  on 9999  degrees of freedom
## Residual deviance:  7286.1  on 9984  degrees of freedom
## AIC: 7318.1
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dir.create}\NormalTok{(}\StringTok{"models"}\NormalTok{, }\AttributeTok{showWarnings =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{dir.create}\NormalTok{(}\StringTok{"data"}\NormalTok{,   }\AttributeTok{showWarnings =} \ConstantTok{FALSE}\NormalTok{)}

\FunctionTok{saveRDS}\NormalTok{(outcome.}\FloatTok{3.}\NormalTok{logistic, }\StringTok{"models/outcome\_3\_logistic.rds"}\NormalTok{)}
\FunctionTok{saveRDS}\NormalTok{(claimsize.}\FloatTok{3.}\NormalTok{gamma,   }\StringTok{"models/claimsize\_3\_gamma.rds"}\NormalTok{)}
\FunctionTok{saveRDS}\NormalTok{(data,                 }\StringTok{"data/training\_data.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}


\end{document}
