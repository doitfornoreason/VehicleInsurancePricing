block_maxima_df <- GEVdf %>%
group_by(blocks) %>%
summarise(
max_claim = max(nonzerosizes)
)
gev_fit <- extRemes::fevd(block_maxima_df$max_claim)
summary(gev_fit)
plot(gev_fit)
# Hypothesis test with H0: shape = 0
# Assuming a normal distribution of the shape parameter estimator
shape.estimate <- 0.219102
shape.stderr <- 0.101009
print(shape.estimate/shape.stderr)
# lognormal
# lm is equivalent to fitting glm(., gaussian(link = identity))
lognormal_claimsize_df <- train_data_imputed[train_data_imputed$OUTCOME >0,] %>%
select(-OUTCOME)
names(train_data_imputed)
lognormal_claimsize_df$CLAIMS <- log(lognormal_claimsize_df$CLAIMS)
# base model no interactions
claimsize.0.lognormal <- lm(CLAIMS ~.,
data = lognormal_claimsize_df)
names(train_data_x)
# model with interactions
claimsize.1.lognormal <- lm(CLAIMS ~(AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION +
CREDIT_SCORE + VEHICLE_OWNERSHIP + VEHICLE_YEAR +
MARRIED + CHILDREN + ANNUAL_MILEAGE +
VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2,
data = lognormal_claimsize_df)
par(mfrow = c(2,2))
print('---------------------FULL MODEL NO INTERACTION TERMS------------------------')
summary(claimsize.0.lognormal);plot(claimsize.0.lognormal)
print('----------------WHITE TEST-----------------------------')
white_test(claimsize.0.lognormal)
print('-----------------VIF----------------------------')
vif(claimsize.0.lognormal, type = "predictor")
# backward selection
print('----------------------backward----------------------')
print('adjr2')
lognormal_bwdselection <- stats::step(claimsize.1.lognormal, direction = "backward", trace = 0)
summary(lognormal_bwdselection)
claimsize.2.lognormal <- lognormal_bwdselection
# between full model with all interaction terms and backward stepwise model
anova(claimsize.2.lognormal,claimsize.1.lognormal)
# plot of type 1 standardised residuals
hist(summary(claimsize.2.lognormal)$res/ summary(claimsize.2.lognormal)$sigma, breaks = 100,
main = "histogram of standardised residuals", xlab = "standardised residuals")
claimsize_df <- train_data_imputed[train_data_imputed$OUTCOME >0,] %>%
select(-OUTCOME)
# base model no interaction
claimsize.0.gamma <- glm(CLAIMS ~. , family = Gamma(link = "log"),
data = claimsize_df)
# w interactions
claimsize.1.gamma <- glm(CLAIMS ~(AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION +
CREDIT_SCORE + VEHICLE_OWNERSHIP + VEHICLE_YEAR +
MARRIED + CHILDREN + ANNUAL_MILEAGE +
VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2, family = Gamma(link = "log"),
data = claimsize_df)
par(mfrow = c(2,2))
print('---------------------FULL MODEL NO INTERACTION TERMS------------------------')
summary(claimsize.0.gamma);plot(claimsize.0.gamma)
print('----------------WHITE TEST-----------------------------')
white_test(claimsize.0.gamma)
print('-----------------VIF----------------------------')
vif(claimsize.0.gamma, type = "predictor")
df <- claimsize_df
# Ensure positivity
stopifnot(all(df$CLAIMS > 0), all(is.finite(df$CLAIMS)))
# Make sure all categorical vars are factors, then drop unused levels
char_cols <- sapply(df, is.character)
df[char_cols] <- lapply(df[char_cols], factor)
df <- droplevels(df)
upper_form <- CLAIMS ~ (AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION +
CREDIT_SCORE + VEHICLE_OWNERSHIP + VEHICLE_YEAR +
MARRIED + CHILDREN + ANNUAL_MILEAGE +
VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2
# Start with a converged base model (intercept + main effects is a good start)
base_form <- CLAIMS ~ AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION +
CREDIT_SCORE + VEHICLE_OWNERSHIP + VEHICLE_YEAR +
MARRIED + CHILDREN + ANNUAL_MILEAGE +
VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS
gamma_base <- glm(base_form, family = Gamma(link = "log"),
data = df, control = glm.control(maxit = 100))
# Forward or both-direction stepwise within scope; pass control so refits get more iterations
gamma_step <- stats::step(gamma_base,
scope = list(lower = ~1, upper = upper_form),
direction = "both",
trace = 0,
control = glm.control(maxit = 70))
summary(gamma_step)
cat("\n\n--- Generating Diagnostic Plots for Final Model ---\n")
claimsize.2.gamma <- gamma_step
par(mfrow = c(2, 2))
plot(claimsize.2.gamma)
exp(coef(claimsize.2.gamma))
print("--------------------------------")
vif(claimsize.2.gamma)
# between full model and stepwise selected
anova(claimsize.2.gamma, claimsize.1.gamma, test = "LRT")
# histogram of type 1 standardised residuals
hist(rstandard(claimsize.2.gamma), breaks = 100)
model_diagnostics <- augment(claimsize.2.gamma,
data = claimsize_df)
# Calculate the Cook's distance threshold
n <- nrow(claimsize_df)
cooks_threshold <- 4 / n
print(paste('cooks threshold is ', cooks_threshold))
# Find the observations that exceed this threshold
influential_points <- model_diagnostics %>%
filter(.cooksd > cooks_threshold) %>%
arrange(desc(.cooksd))
print(influential_points)
# investigating influential points further
# correlation between variables when influential
num_cols <- influential_points %>%
dplyr::select(where(is.numeric))
corrplot(cor(num_cols), type = "lower", diag = F,tl.cex = 0.7)
#histogram
for (i in 1:length(influential_points)){
covariate <- influential_points[[i]]
if (is.numeric(covariate)){
hist(covariate, main = paste("Histogram of", names(influential_points)[i] ), xlab = deparse(substitute(covariate)), breaks = 80)
}
}
# plotting influential points
ggplot(model_diagnostics, aes(x = .hat, y = .std.resid)) +
# Points are sized by their Cook's distance
geom_point(aes(size = .cooksd), alpha = 0.5, shape = 1) +
# Add a smoother to see the general trend
geom_smooth(se = FALSE, col = "dodgerblue") +
# Highlight the most influential points found earlier
geom_point(data = influential_points, aes(size = .cooksd), color = "red") +
# Add labels to the influential points (e.g., by row number)
geom_text(data = influential_points, aes(label = rownames(influential_points)),
vjust = -1, color = "red") +
# Add a horizontal line at 0
geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
# Add labels and a title
labs(
title = "Influence Plot: Residuals vs. Leverage",
subtitle = "Points sized by Cook's Distance. Red points are highly influential.",
x = "Leverage (Hat Values)",
y = "Standardized Deviance Residuals",
size = "Cook's D"
) +
theme_minimal()
influential_rows <- as.numeric(rownames(influential_points))
claimsize_df_no_influencers <- claimsize_df[-influential_rows, ]
model_without_influencers <- glm(formula(claimsize.2.gamma),
family = Gamma(link = "log"),
data = claimsize_df_no_influencers)
comparison <- cbind(Original = coef(claimsize.2.gamma),
No_Influencers = coef(model_without_influencers))
print(comparison)
c(Original_Dispersion = summary(claimsize.2.gamma)$dispersion, No_Influencers_Dispersion = summary(model_without_influencers)$dispersion)
# Helper: coerce factor levels in newdata to training levels stored in the fit
prep_newdata_for <- function(newdata, fit) {
nd <- newdata
if (!is.null(fit$xlevels)) {
for (nm in names(fit$xlevels)) {
if (nm %in% names(nd)) {
nd[[nm]] <- factor(nd[[nm]], levels = fit$xlevels[[nm]])
}
}
}
droplevels(nd)
}
# 1) Test set for severity evaluation (only positive claims)
test_claimsize_df <- test_data_imputed |>
dplyr::filter(CLAIMS > 0)
# 2) Align test data to each model
test_for_gamma    <- prep_newdata_for(test_claimsize_df, claimsize.2.gamma)
test_for_lognorm  <- prep_newdata_for(test_claimsize_df, claimsize.2.lognormal)
# 3) Predictions
# Gamma(log): already on the dollar scale
pred_gamma <- predict(claimsize.2.gamma, newdata = test_for_gamma, type = "response")
# Lognormal (lm on log(CLAIMS)): use smearing correction
pred_log <- predict(claimsize.2.lognormal, newdata = test_for_lognorm)  # predicts log(CLAIMS)
# Duanâ€™s smearing factor from TRAINING residuals of the log model
sf <- mean(exp(residuals(claimsize.2.lognormal)), na.rm = TRUE)
pred_lognormal <- exp(pred_log) * sf
# 4) Metrics
actual_claims <- test_for_lognorm$CLAIMS
rmse <- function(a, p) sqrt(mean((a - p)^2, na.rm = TRUE))
mae  <- function(a, p) mean(abs(a - p), na.rm = TRUE)
rmse_gamma <- rmse(actual_claims, pred_gamma)
mae_gamma  <- mae(actual_claims, pred_gamma)
rmse_lognormal <- rmse(actual_claims, pred_lognormal)
mae_lognormal  <- mae(actual_claims, pred_lognormal)
comparison_df <- data.frame(
Model = c("Gamma GLM", "Lognormal (lm + smearing)"),
RMSE  = c(rmse_gamma, rmse_lognormal),
MAE   = c(mae_gamma,  mae_lognormal)
)
print(comparison_df)
# plot errors
hist(pred_gamma - actual_claims, breaks = 100, xlim = c(-80000, 40000),
main = 'gamma model errors')
hist(pred_lognormal - actual_claims, breaks = 100, xlim = c(-80000, 40000),
main = 'lognormal model errors')
# computing average errors
print(paste("gamma model", mean(pred_gamma - actual_claims)))
print(paste("lognormal model", mean(pred_lognormal - actual_claims)))
# observing tail behaviours of the errors
gamma_model_errors <- pred_gamma - actual_claims
gamma_model_errors_tail <- abs(gamma_model_errors[gamma_model_errors  < (-10)])
lognormal_model_errors <- pred_lognormal - actual_claims
lognormal_model_errors_tail <- abs(lognormal_model_errors[lognormal_model_errors  < (-10)])
# --- 1. Define Your Data and Names ---
# Replace these placeholder vectors with your actual data
vector1 <- gamma_model_errors_tail # e.g., errors_gamma
vector2 <- lognormal_model_errors_tail   # e.g., errors_lognormal
# Define names for the legend
name1 <- "Gamma Model Errors"
name2 <- "Lognormal Model Errors"
# --- Plot 1: Log-Log Survival Plot ---
ecdf_x <- ecdf(vector1)
data_x <- data.frame(val = sort(unique(vector1))) %>% mutate(prob = 1 - ecdf_x(val)) %>% filter(prob > 0)
ecdf_y <- ecdf(vector2)
data_y <- data.frame(val = sort(unique(vector2))) %>% mutate(prob = 1 - ecdf_y(val)) %>% filter(prob > 0)
xlim_range <- range(c(data_x$val, data_y$val))
ylim_range <- range(c(data_x$prob, data_y$prob))
plot(data_x$val, data_x$prob, type = "p", log = "xy", col = "dodgerblue", lwd = 2,
xlim = xlim_range, ylim = ylim_range, main = "Log-Log Survival Plot",
xlab = "Value (log scale)", ylab = "P(Value > x) (log scale)")
points(data_y$val, data_y$prob, col = "firebrick", lwd = 2, lty = 2)
legend("bottomleft", legend = c(name1, name2), col = c("dodgerblue", "firebrick"), lty = c(1, 2), lwd = 2, bty = "n")
# --- Plot 2: Mean Excess Plot ---
mean_excess_func <- function(data) {
thresholds <- unique(sort(data))
excess <- sapply(thresholds, function(u) { mean(data[data > u] - u) })
return(data.frame(threshold = thresholds, mean_excess = excess))
}
me_x <- mean_excess_func(vector1)
me_y <- mean_excess_func(vector2)
xlim_range_me <- range(c(me_x$threshold, me_y$threshold))
ylim_range_me <- range(c(me_x$mean_excess, me_y$mean_excess), na.rm = TRUE)
plot(me_x$threshold, me_x$mean_excess, type = "l", col = "dodgerblue", lwd = 2,
xlim = c(0, 20000), ylim = ylim_range_me, main = "Mean Excess Plot",
xlab = "Threshold (u)", ylab = "Mean Excess over Threshold e(u)")
lines(me_y$threshold, me_y$mean_excess, col = "firebrick", lwd = 2, lty = 2)
legend("topleft", legend = c(name1, name2), col = c("dodgerblue", "firebrick"), lty = c(1, 2), lwd = 2, bty = "n")
# AIC for the Gamma(GLM) model (already on Y-scale)
aic_gamma <- AIC(claimsize.2.gamma)
# AIC for the lognormal model from lm(log(CLAIMS) ~ ...)
# Convert the lm to a lognormal likelihood on Y
mf_ln  <- model.frame(claimsize.2.lognormal)
y_log  <- model.response(mf_ln)               # = log(CLAIMS)
y      <- exp(y_log)                          # original scale
mu_log <- fitted(claimsize.2.lognormal)       # mean on log scale
sdlog  <- sigma(claimsize.2.lognormal)        # residual SD on log scale
ll_lognorm <- sum(dlnorm(y, meanlog = mu_log, sdlog = sdlog, log = TRUE))
k_lognorm  <- length(coef(claimsize.2.lognormal)) + 1  # +1 for sd
aic_lognorm <- -2 * ll_lognorm + 2 * k_lognorm
# (Equivalent shortcut: aic_lognorm <- AIC(claimsize.2.lognormal) + 2 * sum(log(y)))
# Compare
aics <- c(Gamma = aic_gamma, Lognormal = aic_lognorm)
delta <- aics - min(aics)
akaike_wt <- exp(-0.5 * delta) / sum(exp(-0.5 * delta))
data.frame(Model = names(aics), AIC = aics, DeltaAIC = delta, AkaikeWeight = akaike_wt)
# QQ Plot against Exponential (for tail diagnosis)
qqtail <- function(vec, col, add=FALSE, ...) {
n <- length(vec)
sorted <- sort(vec)
k <- floor(0.1 * n)
tail <- sorted[(n-k+1):n]
qexp <- qexp(ppoints(k), rate=1/mean(tail - min(tail)))
if (!add) {
plot(qexp, tail, col=col, pch=16, xlab="Theoretical Quantiles (Exp)",
ylab="Sample Quantiles", main="QQ Plot (Tail)", ...)
} else {
points(qexp, tail, col=col, pch=16)
}
}
qqtail(gamma_model_errors_tail, "blue")
qqtail(lognormal_model_errors_tail, "red", add=TRUE)
legend("topleft", legend=c("Gamma errors", "Lognormal errors"), col=c("blue", "red"), pch=16)
# Hill Plot (Pareto tail index estimator)
hillplot <- function(vec, col, add=FALSE, ...) {
sorted <- sort(vec, decreasing=TRUE)
n <- length(vec)
k <- 2:(n-1)
hill <- sapply(k, function(i) mean(log(sorted[1:i])) - log(sorted[i]))
if (!add) {
plot(k, hill, type="l", col=col, lwd=2,
xlab="Order Statistics k", ylab="Hill Estimator", main="Hill Plot", ...)
} else {
lines(k, hill, col=col, lwd=2)
}
}
hillplot(gamma_model_errors_tail, "blue")
hillplot(lognormal_model_errors_tail, "red", add=TRUE)
legend("topright", legend=c("Gamma errors", "Lognormal errors"), col=c("blue", "red"), lwd=2)
# Maximum-to-Sum Plot (finite moments check)
max2sumplot <- function(vec, col, add=FALSE, ...) {
n <- length(vec)
k <- 1:n
maxvals <- sapply(k, function(i) max(vec[1:i]))
sumvals <- sapply(k, function(i) sum(vec[1:i]))
ratio <- maxvals/sumvals
if (!add) {
plot(k, ratio, type="l", col=col, lwd=2,
xlab="Sample Size", ylab="Max/Sum", main="Maximum-to-Sum Plot", ...)
} else {
lines(k, ratio, col=col, lwd=2)
}
}
max2sumplot(gamma_model_errors_tail, "blue")
max2sumplot(lognormal_model_errors_tail, "red", add=TRUE)
legend("topright", legend=c("Gamma errors", "Lognormal errors"), col=c("blue", "red"), lwd=2)
claimoutcome_df <- train_data_imputed %>%select(-CLAIMS)
mean(claimoutcome_df$OUTCOME)
# full basic model without interaction terms
outcome.0.logistic <- glm(OUTCOME ~ .,
family = binomial(link = "logit"),
data = claimoutcome_df)
# full model with interaction terms
outcome.1.logistic <- glm(OUTCOME ~(AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION +
CREDIT_SCORE + VEHICLE_OWNERSHIP + VEHICLE_YEAR +
MARRIED + CHILDREN + ANNUAL_MILEAGE +
VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2,
family= binomial(link = "logit"),
data = claimoutcome_df)
# Stepwise (both) from null -> up to the full formula of outcome.1.logistic
logistic_both <- stats::step(
update(outcome.1.logistic, . ~ 1),                       # start: intercept-only (same data/family)
scope = list(lower = ~ 1, upper = formula(outcome.1.logistic)),
direction = "both",
trace = 0,
k = log(nobs(outcome.1.logistic))                         # BIC; use k = 2 for AIC
)
summary(logistic_both)
# Final chosen model
outcome.2.logistic <- logistic_both
# Align both models to the exact same rows used in the full model
mf <- model.frame(outcome.1.logistic)
reduced <- update(outcome.2.logistic, data = mf)
# Likelihood-ratio test (valid when reduced is nested in full)
anova(reduced, outcome.1.logistic, test = "Chisq")
# AIC and BIC (smaller is better)
AIC(reduced, outcome.1.logistic)
n <- nobs(outcome.1.logistic)
AIC(reduced, outcome.1.logistic, k = log(n))  # BIC
hist(residuals(outcome.2.logistic, type = "deviance"), main = "Histogram of Deviance Residuals", xlab = "Deviance Residuals", breaks = 100)
qres <- qresiduals(outcome.2.logistic)
par(mfrow = c(1, 2)) # Set up a 1x2 plotting area
hist(qres, main = "Histogram of Quantile Residuals", xlab = "Quantile Residuals")
qqnorm(qres, main = "Normal Q-Q Plot")
qqline(qres, col = "red", lty = 2)
# full basic model without interaction terms
outcome.0.probit <- glm(OUTCOME ~ .,
family = binomial(link = "probit"),
data = claimoutcome_df)
# full model with interaction terms
outcome.1.probit <- glm(OUTCOME ~(AGE + GENDER + DRIVING_EXPERIENCE + EDUCATION +
CREDIT_SCORE + VEHICLE_OWNERSHIP + VEHICLE_YEAR +
MARRIED + CHILDREN + ANNUAL_MILEAGE +
VEHICLE_TYPE + SPEEDING_VIOLATIONS + PAST_ACCIDENTS)^2,
family = binomial(link = "probit"),
data = claimoutcome_df)
probit_both <- stats::step(
update(outcome.1.probit, . ~ 1),  # start from intercept-only
scope = list(lower = ~ 1, upper = formula(outcome.1.probit)),
direction = "both",
trace = 0,
k = log(nobs(outcome.1.probit))   # BIC; use k = 2 for AIC
)
summary(probit_both)
# Final chosen model
outcome.2.probit <- probit_both
# Ensure both models use identical rows
mf <- model.frame(outcome.1.probit)
reduced <- update(outcome.2.probit, data = mf)
# Likelihood-ratio test (Model 1 = reduced, Model 2 = full)
anova(reduced, outcome.1.probit, test = "Chisq")
# AIC and BIC comparison (smaller is better)
AIC(reduced, outcome.1.probit)
n <- nobs(outcome.1.probit)
AIC(reduced, outcome.1.probit, k = log(n))  # BIC
# Helpers
prep_newdata_for <- function(newdata, fit) {
nd <- newdata
if (!is.null(fit$xlevels)) {
for (nm in names(fit$xlevels)) if (nm %in% names(nd)) {
nd[[nm]] <- factor(nd[[nm]], levels = fit$xlevels[[nm]])
}
}
droplevels(nd)
}
log_loss <- function(y, p, eps = 1e-15) {
p <- pmin(pmax(p, eps), 1 - eps)
-mean(y * log(p) + (1 - y) * log(1 - p), na.rm = TRUE)
}
brier <- function(y, p) mean((p - y)^2, na.rm = TRUE)
calibration_df <- function(y, p, bins = 10, label = "model") {
brks <- quantile(p, probs = seq(0, 1, length.out = bins + 1), na.rm = TRUE)
g <- cut(p, breaks = unique(brks), include.lowest = TRUE)
dplyr::summarise(dplyr::group_by(data.frame(y, p, g), g),
mean_p = mean(p, na.rm = TRUE),
obs   = mean(y, na.rm = TRUE),
n     = dplyr::n()) |>
mutate(model = label)
}
# Prepare test data for each model (handles factors/levels)
test_logit  <- prep_newdata_for(test_data_imputed, outcome.2.logistic)
test_probit <- prep_newdata_for(test_data_imputed, outcome.2.probit)
# Predictions
y  <- test_logit$OUTCOME
p_logit  <- predict(outcome.2.logistic, newdata = test_logit,  type = "response")
p_probit <- predict(outcome.2.probit,   newdata = test_probit, type = "response")
# Keep rows where both models produce probabilities
keep <- is.finite(p_logit) & is.finite(p_probit) & !is.na(y)
y <- y[keep]; p_logit <- p_logit[keep]; p_probit <- p_probit[keep]
# Build ROC objects with pROC
roc_logit  <- pROC::roc(y, p_logit,  quiet = TRUE)
roc_probit <- pROC::roc(y, p_probit, quiet = TRUE)
# Get numeric AUCs (either of these styles works)
auc_logit  <- as.numeric(pROC::auc(roc_logit))
auc_probit <- as.numeric(pROC::auc(roc_probit))
# or:
# auc_logit  <- as.numeric(roc_logit$auc)
# auc_probit <- as.numeric(roc_probit$auc)
metrics <- data.frame(
Model   = c("Logit", "Probit"),
AUC     = c(auc_logit, auc_probit),
LogLoss = c(log_loss(y, p_logit),  log_loss(y, p_probit)),
Brier   = c(brier(y, p_logit),     brier(y, p_probit))
)
print(metrics, row.names = FALSE)
# AUC difference test
auc_test <- pROC::roc.test(roc_logit, roc_probit, method = "delong")
cat(sprintf("\nDeLong test for AUC difference: z = %.3f, p = %.4f\n",
auc_test$statistic, auc_test$p.value))
# ROC curves (overlaid)
df_roc_logit <- data.frame(
fpr = rev(1 - roc_logit$specificities),
tpr = rev(roc_logit$sensitivities),
model = "Logit"
)
df_roc_probit <- data.frame(
fpr = rev(1 - roc_probit$specificities),
tpr = rev(roc_probit$sensitivities),
model = "Probit"
)
df_roc <- rbind(df_roc_logit, df_roc_probit)
p_roc <- ggplot(df_roc, aes(x = fpr, y = tpr, color = model)) +
geom_line(size = 1) +
geom_abline(slope = 1, intercept = 0, linetype = 2, color = "gray50") +
labs(title = sprintf("ROC on test (AUC: logit=%.3f, probit=%.3f)",
metrics$AUC[metrics$Model=="Logit"],
metrics$AUC[metrics$Model=="Probit"]),
x = "False Positive Rate", y = "True Positive Rate") +
theme_minimal() + coord_equal()
print(p_roc)
# Calibration (reliability) plot
cal_logit  <- calibration_df(y, p_logit,  bins = 10, label = "Logit")
cal_probit <- calibration_df(y, p_probit, bins = 10, label = "Probit")
cal <- rbind(cal_logit, cal_probit)
p_cal <- ggplot(cal, aes(x = mean_p, y = obs, color = model, size = n)) +
geom_point(alpha = 0.85) +
geom_abline(slope = 1, intercept = 0, linetype = 2, color = "gray50") +
scale_size_continuous(name = "Bin N") +
labs(title = "Calibration on test (10 quantile bins)",
x = "Mean predicted probability", y = "Observed frequency") +
theme_minimal()
print(p_cal)
# Optional: density of predicted probabilities by class (separation plot)
df_prob <- data.frame(y = factor(y, levels = c(0,1)),
logit = p_logit, probit = p_probit) |>
tidyr::pivot_longer(cols = c(logit, probit), names_to = "model", values_to = "p")
p_den <- ggplot(df_prob, aes(x = p, fill = y)) +
geom_density(alpha = 0.35) +
facet_wrap(~ model, ncol = 1) +
labs(title = "Predicted probability densities by outcome (test)",
x = "Predicted probability", y = "Density", fill = "Outcome") +
theme_minimal()
print(p_den)
# kNN-impute numeric predictors and refit models on data_imputed
# Predictors used by either model (exclude responses)
pred_vars <- setdiff(
unique(c(all.vars(formula(outcome.2.logistic))[-1],
all.vars(formula(claimsize.2.gamma))[-1])),
c("OUTCOME", "CLAIMS")
)
# Numeric predictors to impute
num_vars <- intersect(pred_vars, names(Filter(is.numeric, data)))
# Train kNN imputer (k = 5) on training numerics and impute
rec <- recipe(~ ., data = data[, num_vars, drop = FALSE]) |>
step_impute_knn(all_predictors(), neighbors = 5)
imp <- prep(rec, training = data[, num_vars, drop = FALSE], retain = TRUE)
data_imputed <- data
data_imputed[, num_vars] <- bake(imp, new_data = data[, num_vars, drop = FALSE])
# Refit models with identical specs on imputed data
claimsize.3.gamma  <- update(claimsize.2.gamma,  data = data_imputed[data_imputed$CLAIMS > 0, ])
outcome.3.logistic <- update(outcome.2.logistic, data = data_imputed)
summary(claimsize.3.gamma)
exp(coef(claimsize.3.gamma))  # multiplicative effects on mean CLAIMS
summary(outcome.3.logistic)
dir.create("models", showWarnings = FALSE)
dir.create("data",   showWarnings = FALSE)
saveRDS(outcome.3.logistic, "models/outcome_3_logistic.rds")
saveRDS(claimsize.3.gamma,   "models/claimsize_3_gamma.rds")
saveRDS(data,                 "data/training_data.rds")
cat("Saving required objects to 'app_dependencies.RData'...\n")
save(data,
outcome.3.logistic,
claimsize.3.gamma,
data,
file = "app_dependencies.RData")
cat("Objects saved successfully.\n")
shiny::runApp('app')
runApp('app')
